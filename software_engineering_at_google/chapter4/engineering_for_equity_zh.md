# 工程的平等性

在前面的章节中，我们已经探讨了编程和软件工程的差别。编程是指解决当前问题的代码产品，而软件工程将代码、工具、策略和过程更广泛地应用于一个动态的、模糊的问题，这个问题可能跨越几十年甚至几十年。在本章中，我们将讨论工程师在为广大用户设计产品时的独特职责。此外，我们将评估一个项目团队如何通过多元融合来设计适合每个人的系统，避免对我们的部分用户造成永久的伤害。

尽管软件工程领域很新，但对于软件工程对特殊人群和多样化社会的产生的影响我们依然有深刻的理解。我们知道所有的答案，所以我们没有写这一章。事实上，谷歌正在尝试充分理解如何设计一个产品，使我们的所有用户拥有使用权并获得尊重。过去，在保护我们最敏感的用户的实践中，我们有许多失败的案例，所以我们写了这一章，因为通向设计更包容的产品的道路往往需要复盘我们的失败经历和鼓励持续成长。

我们之所以写下这一章，也是因为那些做出影响世界发展的决策的人与那些必须接受并依赖这些决策生存的人之间的力量日益失衡，这些决策有时对那些全球已经被边缘化的团体不利。与下一代软件工程师分享和反思我们迄今为止学到的东西很重要。更重要的是，我们要致力于影响下一代工程师，让他们比今天的我们更优秀。

拿起这本书就意味着你可能渴望成为一名杰出的工程师。你想解决问题，你渴望为最广泛的人群(包括最难接触到的人群)打造能带来良好效果的产品。为此，您将需要考虑如何利用自己构建的工具来改变人类的轨迹，以期变得更好。

## 偏见是必然存在的

当工程师不关注不同国籍、民族、种族、性别、年龄、社会经济地位、能力和信仰体系的用户时，即使是最有才华的员工也会在无意中辜负他们的用户。这种失败往往是无意的，所有人都有一定的偏见。社会科学家在过去几十年中已经认识到，大多数人表现出无意识的偏见，表现为强化和传播现有的陈旧观念。无意识的偏见是暗中为害的，通常比有意的排斥行为更难减轻。即使我们想做正确的事情，我们也可能认识不到自己的偏见。同样，我们的团队也必须认识到这种偏见的存在，并努力在员工、产品开发和用户推广中解决这一问题。

由于偏见的存在，谷歌有时无法使其产品对所有用户平等相待，过去几年发布的产品没有充分关注不具有普遍代表性的群体。许多用户将我们在这些情况下缺乏平等意识归因于这样一个事实，即我们的工程人员大多是男性，大多是白人或亚洲人，当然也就不能代表所有使用我们产品的人群。这些特殊用户在我们的员工中缺乏代表性，这意味着我们通常不会多元的理解使用我们的产品会如何影响到代表性不足或易受伤害的用户。

>**案例研究:谷歌错过了多种族含括的特征**
>
>2015年，软件工程师杰克·阿尔辛指出，谷歌照片中的图像识别算法将他的黑人朋友归类为“大猩猩”。谷歌对这些错误的回应很慢，并且解决这些问题也不完全。
>
>是什么导致了如此巨大的失败？几个原因:
>
>图像识别算法依赖于被提供的“合适的”(通常意味着“完整的”)数据集。输入谷歌图像识别算法的照片数据显然是不完整的。简而言之，数据不代表全部人群。
>
>谷歌本身(以及整个科技行业)一直以来都没有太多的黑人工程师代表，这使得设计这种算法和收集数据集时具有主观性。团队本身无意识的偏见很可能导致更具普遍代表性的产品被搁置。
>
>谷歌图像识别的目标市场没有充分包括这些普遍代表性不足的群体，谷歌的测试没有抓住这些错误。结果，我们不具有普遍代表性的用户使用了该产品，这既让谷歌难堪，也伤害了我们的用户。
>
>直到2018年，谷歌仍未充分解决潜在的问题。

在这个例子中，我们的产品没有得到充分的设计和执行，没有适当地考虑所有的种族群体，结果，辜负了我们的用户，并造成了谷歌的负面新闻。其他技术也遭受了类似的失败，例如自动完成的结果中可能返回带有攻击性或种族主义，谷歌的广告系统可能被操纵来显示种族主义或攻击性的广告，YouTube可能不会捕捉到仇恨言论，尽管在该平台上这些言论是违法的。

在所有这些情况下，技术本身并不是罪魁祸首。例如， ‘’自动完成‘’不是为了针对特定用户或歧视而设计的。但是它在设计上还没有足够的适应力来排除被视为仇恨言论的歧视性语言。 结果，该算法返回了对我们的用户造成伤害的结果。 对Google本身的危害也应该显而易见：降低用户对公司的信任和参与度。例如，黑人、拉丁人和犹太人应聘者可能会对谷歌这个平台甚至是拥有一个包容性的环境失去信心，因此破坏了谷歌提高招聘人群普遍代表性的目标。

为什么会这样呢？毕竟，谷歌雇佣的技术人员受过无可挑剔的教育和/或有专业经验——优秀的程序员写出最好的代码并测试他们的工作。“为所有人而生”是谷歌的品牌声明，但事实是，在我们声称我们做到之前，我们还有很长的路要走。解决这些问题的一个方法是帮助软件工程组织群体本身看起来像我们构建产品的目标人群。

## 理解多样性的必要性

在谷歌，我们认为，作为一名杰出的工程师，你还需要专注于将不同的视角引入产品设计和实施。这也意味着负责招聘或面试其他工程师的谷歌人必须致力于打造更具普遍代表性的员工队伍。例如，如果你面试应聘你公司职位的其他工程师，了解在招聘中出现有偏见的结果是如何发生的是很重要的。理解如何预测伤害和预防伤害需要重要的预备知识。为了达到我们的项目可以为每个人建设的程度，我们首先必须了解我们的代表的人群，同时需要鼓励工程师接受更广泛的教育培训。

职场中最重要的一点是打破这样一种观念，即作为一个拥有计算机科学学位和/或工作经验的人，你拥有成为卓越工程师所需的所有技能。计算机科学学位通常是必要的基础，但是，仅仅只有学历(即使加上工作经验)并不能让你成为工程师。打破只有拥有计算机科学学位的人才能设计和制造产品的想法也很重要。今天，大多数程序员确实有计算机科学学位；他们是编写代码的高手，建立了与时俱进的理论体系，应用各种各样的方法解决问题。然而，如上述例子所示，这些不足以实现包容和平等的工程。

工程师应首先将所有工作集中在他们寻求影响的整个生态系统的框架内。至少，他们需要了解其用户的人口地理信息。 工程师应专注于与自己截然不同的人，尤其是那些可能试图使用其产品并被伤害的人。 最难考虑的是那些被他们获得技术的流程和环境剥夺了权利的用户。 为了应对这一挑战，工程团队需要代表他们现有的和未来的用户。 在工程团队却反多元文化代表的情况下，各个工程师都需要学习如何为所有用户进行构建项目。

## 建设多元文化能力

杰出工程师的一个标志是能够理解产品如何对不同的人群产生有利和不利的影响。工程师应该有技术才能，但他们也应该有辨别能力，知道什么时候构建什么东西，什么时候不构建。辨别能力包括养成识别和拒绝会导致不良结果的功能或产品的能力。这是一个崇高而艰难的目标，因为成为一名优秀的工程师需要大量的个人主义。为了取得成功，我们必须将关注点扩展到我们自己的团队之外，扩展到下一个十亿用户或当前可能因我们的产品而被剥夺权利或被其抛弃的用户。

随着时间的推移，您可能会创建数十亿人每天使用的工具，这些工具可能会影响人们对人生价值的看法，监视人类活动，捕获并保留敏感数据（例如孩子和爱人的图像）， 以及其他类型的敏感数据。 作为一名工程师，您可能会发挥比您能意识到的更大的力量，这是真正改变社会的力量。 在你成为一名杰出工程师的过程中，理解运用力量而不对用户造成伤害所需的内在责任是至关重要的。 要成为杰出工程师，第一步是要认识到许多社会和教育因素导致的偏见是本身就存在的。认识到这一点后，您将会常常考虑那些被遗忘的用例或用户，他们会从您创建的产品中受益或受伤害。

行业不断向前发展，以越来越快的速度为人工智能和机器学习构建新的用例。为了保持竞争力，我们努力打造一支高素质的工程和技术人才队伍。我们需要停下来考虑这样一个事实，今天，有些人有能力设计技术的未来，而另一些人则没有。我们需要了解我们创建的软件系统是否会消除全部人群共享繁荣和平等获取技术的可能性。

从历史上看，公司面临实现战略目标和创建平等工程之间的抉择，提高市场支配地位和收入的战略目标可以繁荣公司，增加股东价值，但会减慢实现创建平等工程这一目标的势头。 许多公司重视个人的绩效和卓越表现，却往往无法有效地推动产品在各个领域的问责制，从而加剧了这种倾向。 关注代表性不足的用户显然是促进平等的机会。为了在技术领域继续保持竞争力，我们需要学会为全球平等而努力。

如今，我们对公司创造技术来扫描、捕捉和识别街上行人感到担忧。我们担心隐私问题以及政府如何使用这些信息。大多数技术专家没有从特殊群体的必要视角来理解面部识别中种族差异的影响，没有理清如何应用人工智能将会得到有害或不准确结果的问题。

目前，人工智能驱动的面部识别软件任然对有色人种或少数族裔不利。我们的研究不够全面，没有广泛的包括足够的不同肤色。如果训练数据和创建软件的数据都只代表一小部分人，我们就不能期望输出是有效的。在这种情况下，我们应该主动推迟开发进度，以获得更完整和准确的数据，得到更全面和包容的产品。

然而，数据科学本身对人类来说是具有挑战性的。即使我们选择具有普遍代表性的研究对象，一个训练集仍然会有偏差并产生无效的结果。2016年完成的一项研究发现，超过1.17亿美国成年人在执法面部识别数据库中。由于黑人社区的监管频率和被逮捕率与白人的差异，在面部识别中使用这样的数据库可能会造成有种族偏见的错误率。尽管软件的开发和部署速度正在不断提高，但是独立测试速度却没有加快。要纠正这种严重错误，我们需要放慢开发速度，并确保输入的偏差尽可能小。 Google现在在人工智能上下文中提供有统计的训练，以确保数据集本身没有偏见。

因此，将你的从业经验重心转移到更全面的、多文化的、多种族和性别研究的教育上，这不仅是你的责任，也是你雇主的责任。技术公司必须确保其员工不断获得专业发展，并且这种发展是全面和多学科的。要求不是一个人独自承担起学习其他文化或其他人口统计资料的责任。这个变革要求我们每个人，无论是个人还是作为团队的领导者，都要投资于持续的专业发展，不仅要培养我们的软件开发和领导技能，还要培养我们理解全人类多元文化的能力。

## 使多元性具有可操作性

如果我们认可我们所有人都要为我们在技术部门看到的系统性歧视负责，那么系统性的公平和公正是可以实现的。我们要为系统的错误负责，推迟或取消个人问责制是无效的，而且这也是不负责任的，不是你分内应该推脱的事情。将公司或团队内部的制约多元化发展的因素归咎于不平等的社会问题也是不负责任的。多元化支持者和批评者最喜欢的一句话是这样的：“我们正在努力解决这个问题（穿插着讲一些系统性歧视话题），但问责制很难实现。我们如何改变具有数百年历史的歧视？“这种询问方式绕开了很多的哲学或学术对话，没有集中精力去改善工作条件或克服重重困难。 要建设多元文化，我们要全面了解社会中的不平等体系如何影响我们的工作，尤其是技术部门的工作。

如果您是一名工程经理，正在努力从人数不足的群体中招聘更多人，那么顺应世界上歧视的历史影响是一项有益的学术活动。 但是，至关重要的是，要超越学术讨论的重点并侧重于可取的可量化和可操作的步骤，以推动公平和公正。 例如，作为一名招聘软件工程师经理，您有责任确保您的应聘者是公平的。 候选人的评论中是否有女性或其他代表性不足的群体？ 雇用某人后，您提供了哪些增长机会，机会分配是否公平？ 每个技术主管或软件工程经理都有增加他们团队中资产的方法。 我们必须承认，尽管存在重大的系统挑战，但我们都是系统的一部分，这一点很重要。我们应该解决这个问题。

## 拒绝单一的方法

我们无法提出单一的哲学或方法来解决技术领域不平等问题的解决方案。 我们的问题是复杂和多因素的。 因此，我们必须放弃提高工作场所表现的单一方法，即使这些方法是由我们敬佩的人或具有机构权力的人所提倡的。

在技术行业中，一种珍贵的叙述是，仅通过固定招聘渠道即可解决劳动力中缺乏代表性的问题。 这确实是一个基本步骤，但这不是我们需要解决的直接问题。 例如，我们需要认识到在发展和保留方面的系统性不平等，同时还要关注种族，性别，社会经济和移民状况等方面更具代表性的招聘和教育差异。

在技术行业中，来自代表性不足的群体的许多人每天都要经过机会和进步。 Black +的Google员工流失率超过了其他所有群体的流失率，并混淆了代表目标方面的进展。 如果我们想推动变化并增加代表，我们需要评估我们是否正在创建一个生态系统，所有有抱负的工程师和其他技术专业人员都可以在其中发展。

全面了解整个问题空间对于确定如何解决它至关重要。 从关键数据迁移到雇用有代表性的员工，这一切都是正确的。 例如，如果您是一名工程经理，想雇用更多的女性，则不要只专注于建立人才渠道。 关注于雇用，保留和晋升生态系统的其他方面，以及它对女性的包容性。 考虑一下您的招聘人员是否正在表现出识别男性和女性强者的能力。 如果您管理着一支多元化的工程团队，请着重于心理安全并投资于提高团队的多元文化能力，以使新的团队成员倍受欢迎。

一种今天的常用方法是先为大多数用例构建，把处理边缘用例的改进和特性留到以后再处理。但这种方法是有缺陷的; 它让那些已经在获取技术方面有优势的用户抢先一步，这增加了不平等。当设计接近完成时，忽略所有用户组的考虑是为了降低成为优秀工程师的标准。相反，通过从一开始就构建包容性的设计，并提高开发的开发标准，使工具为那些难以接触到技术的人愉快和可访问，我们增强了所有用户的体验。

为最不像你的用户设计不仅是明智的，而且是一种最佳实践。所有的技术人员，无论在哪个领域，在开发避免对用户不利或代表不足的产品时，都应该考虑到一些务实和直接的下一步。它从更全面的用户体验研究开始。这项研究应该针对多语言、多文化、跨越多个国家、社会经济阶层、能力和年龄范围的用户群体。首先关注最困难或最少表现的用例。

## 挑战现有的流程

挑战自己，建立更公平的系统，而不仅仅是设计更具包容性的产品规格。建立公平的制度有时意味着挑战那些导致无效结果的既定进程。

考虑最近的一个案例，评估其对股权的影响。在谷歌，几个工程团队致力于建立一个全球招聘系统。该系统既支持外部招聘，也支持内部流动。参与其中的工程师和产品经理很好地听取了他们认为的核心用户群体——招聘人员的要求。招聘人员专注于减少招聘经理和求职者浪费的时间，他们向开发团队展示了关注这些人的规模和效率的用例。为了提高效率，招聘人员要求工程团队加入一项功能，一旦内部调动人员表达了对一份工作的兴趣，就会向招聘经理和招聘人员突出表现评级——特别是较低的评级。

从表面上看，加快评估过程和帮助求职者节省时间是一个伟大的目标。那么，潜在的股权关注在哪里呢?有人提出了下列公平问题:

​	•发展性评估是对表现的预测性测量吗?

​	•向未来经理提供的绩效评估是否不带有个人偏见?

​	•绩效评估分数是否跨组织标准化?



如果这些问题的答案是“不”，表现评级仍然可能导致不公平的，因此无效的结果。

当一位杰出的工程师质疑过去的业绩能否预测未来的业绩时，评审团队决定进行一次彻底的评审。最后，我们得出结论，如果找到一个新团队，那些表现不佳的候选人很可能克服糟糕的评价。事实上，他们得到满意或模范的表现评价的可能性与那些从未得到过差评价的候选人是一样的。简而言之，绩效评级仅能指示一个人在被评估时在其给定角色上表现如何。评分虽然是衡量某一特定时期内表现的重要方法，但不能预测未来的表现，也不能用来衡量未来职位的胜任程度，或衡量内部候选人是否适合不同团队。(然而，他们可以用来评估一个员工是否被恰当地安排在当前的团队中;因此，他们可以提供一个机会来评估如何更好地支持内部候选人的发展。)

这一分析无疑占用了大量的项目时间，但积极的折衷是更公平的内部流动过程。

## 数值对比结果

谷歌在招聘方面有着良好的投资记录。正如前面的例子所示，我们还不断地评估我们的流程，以提高公平性和包容性。更广泛地说，我们的核心价值观建立在尊重和对多元化和包容性员工的坚定承诺之上。然而，年复一年，我们也没有找到能够反映全球用户的代表性员工队伍。尽管已有政策和计划支持包容性举措，并促进招聘和晋升方面的卓越表现，但改善公平结果的努力仍在继续。失败点不在于公司的价值观、意图或投资，而在于在实现级别上对这些策略的应用。

旧习惯很难改掉。你今天可能习惯为之设计的用户——那些你习惯从他们那里得到反馈的用户——可能不能代表你需要接触到的所有用户。从不适合女性身体的可穿戴设备到不适合深色皮肤的视频会议软件，我们经常在各种产品中看到这种情况。

那么，出路是什么?

1. 好好照照镜子。谷歌的品牌口号是“为每个人而建”。当我们没有一个具有代表性的员工队伍或首先集中社区反馈的参与模型时，我们如何为每个人构建游戏?我们不能。事实是，我们有时非常公开地未能保护我们最脆弱的用户免受种族主义、反犹和恐同内容的伤害。
2. 不要为所有人设计。构建与每一个人。我们还没有为每一个项目建造。这种工作不是在真空中进行的，当然也不会发生在技术还不能代表整个人口的情况下。也就是说，我们不能收拾行李回家。那么我们如何为所有人创造游戏呢?我们和用户一起构建。我们需要让我们的用户参与到人性的各个层面，并有意识地把最脆弱的社区放在我们的设计的中心。它们不应该是事后才想到的。
3. 为那些最难使用你的产品的用户设计。为那些有额外挑战的人设计产品会让产品更适合所有人。另一种思考方法是:不要为了短期周转而交易股票。
4. 不要以为股本;在整个系统中衡量公平性。认识到决策者也会受到偏见的影响，可能对不平等的原因了解不足。您可能不具备识别或衡量股权问题范围的专业知识。迎合单一用户群可能意味着剥夺其他人的权利;这些权衡可能很难发现，也不可能逆转。与多样性、公平性和包容性方面的专家合作。
5. 改变是可能的。我们今天在技术上面临的问题，从监视到虚假信息再到网络骚扰，真的是势不可挡。我们不能用过去失败的方法或我们现有的技能来解决这些问题。我们需要改变。

## 保持好奇心，勇往直前

通往股权的道路漫长而复杂。然而，我们可以也应该从简单地制造工具和服务，转变为增进我们对我们设计的产品如何影响人类的理解。挑战我们的教育，影响我们的团队和管理者，做更全面的用户研究都是取得进步的途径。尽管改变是不舒服的，通向高绩效的道路可能是痛苦的，但通过协作和创造力是可能的。

最后，作为未来杰出的工程师，我们应该首先关注受偏见和歧视影响最大的用户。共同努力，我们可以通过关注持续改进和承认失败来加速进步。成为一名工程师是一个复杂而持续的过程。我们的目标是做出变革，推动人类向前发展，同时不进一步剥夺弱势群体的权利。作为未来杰出的工程师，我们相信我们可以防止系统未来的故障。

## 总结

开发软件和开发软件组织是一个团队的工作。随着软件组织的扩展，它必须针对其用户基础做出响应并进行充分的设计，在当今互联的计算世界中，这涉及到本地和世界各地的每个人。必须做出更多的努力，使设计软件的开发团队和他们生产的产品都能反映出如此多样化和涵盖范围的一组用户的价值。而且，如果一个工程组织想要扩大规模，它不能忽视代表不足的群体;来自这些小组的工程师不仅增强了组织本身，他们还为软件的设计和实现提供了独特和必要的视角，这些视角对整个世界都是真正有用的。

## TL;DRs 

•偏差是常见的。

•多样化是为全面的用户群进行适当设计的必要条件。

•包容性不仅对改善弱势群体的招聘渠道至关重要，而且对为所有人提供一个真正支持性的工作环境至关重要。

•产品开发速度的评估必须与提供对所有用户都真正有用的产品相比较。放慢速度比发布一个可能对某些用户造成伤害的产品要好。

