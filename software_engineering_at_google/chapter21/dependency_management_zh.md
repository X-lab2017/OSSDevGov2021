[toc]



# 依赖管理

依赖管理（我们无法控制的网络库，程序包和依赖的管理）是软件工程中最难理解且最具挑战性的问题之一。 依赖管理关注以下问题：如何在不同的外部依赖的版本之间进行更新？ 为此，我们如何描述版本？ 我们允许或预期依赖中存在哪些类型的更改？ 我们如何决定何时依赖于其他组织所写的代码？

为了进行比较，这里最相关的主题是源代码控制。 这两个领域都描述了我们如何使用源代码。 源代码管理涵盖了更简单的部分：我们在哪里检入内容？ 我们如何进行构建？ 在我们认可trunk-based的开发的价值之后，对于组织而言，大多数日常源代码控制问题都相当简单：“我有新东西，我要将其添加到哪个目录？”

依赖管理在时间和规模增加了额外的复杂性。在trunk-based控制问题上，当你进行改动时，你需要运行测试并且不影响现有的代码。这在对你使用一个共享代码库时，对事物是如何被使用的，并且可以触发构建和运行测试。依赖管理的重点是解决你掌控范围之外的代码出现变化时应该如何解决，这些代码你没有完全访问或可见性的权利。因为你的外部依赖不能与你的专用代码协调，他们更有可能毁坏你的构建，使你的测试失败。我们如何管理的？难道我们不应该采取外部依赖？我们是否应该要求外部依赖版本之间的强大一致性？我们什么时候更新到新版本？

扩展性使所有这些问题变得更加复杂，我们并不是在谈论单个依赖的导入，在通常情况下，我们依赖于整个外部依赖网络，当我们开始处理依赖网络，很容易碰到两个依赖在某个时间点上不兼容的问题。通常，发生这种情况是因为一个依赖项在没有某些前提的情况下会停止工作，而另一个依赖项则与该前提不兼容。有关如何管理一个单一的外部依赖简单的解决方案通常没有考虑到管理一个大型依赖网络的情况。我们会在本章大量讨论各种不同形式冲突的问题。

源代码控制和依赖管理是由以下问题分隔开的相关问题：“我们是否控制此子项目的开发/更新/管理？”例如，如果公司中的每个团队都有各自的存储库，目标和开发实践，则这些团队的代码的交互和管理将会在依赖管理做出更多的工作，相较于源代码控制。另一方面，具有（虚拟？）单个存储库（monorepo）的大型组织可以通过源代码控制策略进一步扩大规模，这是Google的方法。单独的开源项目当然可以视为单独的组织：未知项目与不必要协作项目之间的相互依赖关系是一个依赖关系管理问题。也许我们在此主题上最有力的建议是：在其他条件相同的情况下，相比依赖管理问题，更倾向于源代码控制问题。如果你可以更广泛地重新定义“组织”（整个公司而不是一个团队），那通常是一个很好的权衡。与依管理相比，源代码控制问题更容易考虑，并且处理起来也简单得多。

随着开放源代码软件（OSS）模型的不断发展并且扩展到新的领域，以及许多流行项目的依赖关系图随着时间的推移不断扩展，依赖管理可能已成为软件工程策略中最重要的问题。我们不再是在API之外的一层或两层上建立的不连接孤岛。现代软件是建立在高耸的依赖支柱上的。但是，仅仅因为我们可以建立这些支柱，并不意味着我们已经弄清楚了如何使用它们，并且能保证随着时间的推移这些支柱能够保持稳定。

在本章中，我们将研究依赖管理的一些特殊挑战，探索不同的解决方案（常见和新颖）及其局限性，并研究使用依赖的现实情况，包括我们在Google中的处理方式。首先要承认所有这些，这一点很重要：我们已经为这个问题投入了大量的思考，并且在重构和维护这些问题方面拥有丰富的经验，这些问题表明了现有方法的实际缺陷。我们没有第一手证据表明这个解决方案在整个组织中都能很好地发挥作用。总的来说，本章总结了我们所知道的行不通（或者至少在更大范围内行不通）以及我们认为有可能取得更好效果的解决方法。我们绝对不保证这里有所有的答案；如果有的话，我们不会将其称为软件工程中最重要的问题之一。

## 为什么依赖管理这么困难？

甚至定义依赖管理问题也向我们提出了一些不同寻常的挑战。在这个领域中，许多不成熟的解决方案都集中在一个过于狭窄的问题表述上：“我们如何导入本地开发的代码可以依赖的程序包？”这是必要但不充分的表述。诀窍不只是找到一种管理依赖关系的方法，还在于如何管理依赖关系及其随时间变化的里依赖网络。有些代码直接需要该网络的某些子集，其中某些仅由传递性依赖项引入。在足够长的时间内，该依赖项网络中的所有节点都将具有新版本，并且其中一些更新将很重要。我们如何管理其余依赖网络的级联升级？或者，特别是，如果我们不控制那些依赖关系，那么我们如何使所有依赖关系的相互兼容版本变得容易呢？我们如何分析依赖网络？我们如何管理该网络，尤其是面对不断增长的依赖关系图时？

### 需求的冲突和菱形依赖

依赖管理中的中心问题突出了从依赖网络而不是单个依赖进行思考的重要性。许多困难源于一个问题：当依赖关系网络中的两个节点有冲突的需求时，但你的组织同时依赖于这两个节点时，会发生什么？出现这种情况的原因有很多，从平台考虑因素（操作系统[OS]，语言版本，编译器版本等）到版本不兼容这类更为平凡的问题。版本不兼容作为无法满足的版本要求的典型示例是菱形依赖问题。尽管我们通常不会在依赖关系图中指明“正在使用哪个版本的编译器”之类的东西，但是这些冲突的需求问题中的大多数都是同构的，就是要向代表此需求的依赖关系图中“添加（隐藏）节点”。 ”因此，我们将主要就菱形依赖来讨论冲突的需求，但请记住，libbase实际上绝对是与依赖关系网络中的两个或多个节点的构建有关的任何软件。菱形依赖关系问题以及其他形式的冲突需求，至少需要三层依赖关系，如图21-1所示。

在此简化模型中，liba和libb都使用libbase，更高级别的组件libuser都使用liba和libb。 如果libbase曾经进行过不兼容的更改，则liba和libb作为独立组织的产品，有可能不会同时更新。 如果liba依赖于新的libbase版本，而libb依赖于旧版本，则libuser（也就是你的代码）没有通用的方法将所有东西组合在一起。 可以形成任意规模的菱形：在依赖关系的整个网络中，如果有一个低层节点需要同时处于两个不兼容的版本中（由于存在来自较高层的两条路径） 这两个版本的节点），就会出现问题。

不同的编程语言在不同程度上容忍了菱形依赖问题。对于某些语言，可以在一个版本中嵌入依赖关系的多个（隔离的）版本：从liba调用libbase可能会调用与从libb调用libbase相同的API的不同版本。例如，Java提供了相当完善的机制来重命名此类依赖关系提供的符号。同时，C ++在正常构建中对菱形依赖关系的容忍度几乎为零，并且它们很可能触发任意错误和未定义的行为（UB ），因为它明显违反了C ++的“一个定义规则”。你最多可以使用与Java类似的方法，将某些符号隐藏在动态链接库（DLL）中，或者在你分别构建和链接的情况下使用。但是，在我们所知道的所有编程语言中，这些解决方案充其量只是一部分的解决方案：可以通过调整函数名称来嵌入多个版本，但如果在依赖关系之间传递了类型，所有努力就都白费了。例如，根本没有办法将libbase v1中定义的map以语义一致的方式通过某些库传递给libbase v2提供的API。在的特定于语言的单独编译的库中隐藏或重命名实体可以为菱形依赖问题提供一定的缓冲，但在一般情况下解决不了问题。

如果遇到冲突的依赖需求问题，唯一简单的答案是向前或向后跳过这些依赖项的版本，以查找兼容的版本。 如果不可能，我们必须在本地解决有问题的依赖关系，这特别具有挑战性，因为首先发现不兼容的工程师可能不知道提供商和使用者之间不兼容的原因。 这是固有的：liba开发人员仍在与libbase v1兼容，并且libb开发人员已升级到v2。 只有同时参与这两个项目的开发人员才有机会发现问题，并且当然不能保证他们对libbase和liba足够熟悉，可以完成升级。 较简单的答案是降级libbase和libb，但是如果最初由于安全性问题而强制升级了，则不可以这样做。

用于依赖管理的策略和技术系统主要归结为以下问题：“我们如何在避免冲突需求的同时仍允许非协调组之间进行更改？” 如果你有解决里菱形依赖问题的一般形式的解决方案，并且可以在网络的各个级别上不断更改需求（依赖关系和平台需求），那么你已经描述了依赖关系管理解决方案的有趣部分。

## 引入依赖

用编程的术语来说，重用一些现有的基础结构显然比自己重新构建它更好。 这是显而易见的，并且是技术基础前进的一部分：如果每个新手都必须重新实现自己的JSON解析器和正则表达式引擎，我们将一事无成。 重用是很好的，特别是与从头开始开发高质量软件的成本相比。 只要你不下载木马软件，如果你的外部依赖满足编程任务的要求，则应使用外部依赖。

### 兼容性承诺

当我们开始考虑时间时，会出现一些更为复杂的取舍。 导入依赖项虽然避免了开发成本，但并不意味着是正确的选择。 但软件工程组织的人员随着时间变化时，我们还需要注意持续维护软件的成本。 即使我们引入了本来无意升级的依赖关系、发现安全漏洞或者改变软件运行平台，无论我们的意图如何，以及不断发展的依赖关系的网络都可以强迫我们进行升级。 在那一天到来时，升级价格会是多少？ 在仅使用某些依赖项的情况下，这些依赖项相比比其他依赖项可以更为明确的确定预期成本：假定了多少兼容性？ 假定改变了多少？ 如何处理变更？ 支持发行多长时间？

考虑拥有数百万用户的大型基础架构项目设置的示例及其兼容性承诺。我们建议依赖提供者应更清楚地了解这些问题的答案。 

#### C++

对于C ++标准库，该模型是几乎不确定的向后兼容性之一。针对较早版本的标准库构建的二进制文件有望与较新的标准构建并链接：该标准不仅提供API兼容性，而且还为二进制文件提供持续的向后兼容性，即ABI兼容性。各个平台对这种支持的重视程度各不相同。对于Linux上的gcc用户而言，大多数代码在大约十年的时间内都可以正常工作。该标准并未明确表示其对ABI兼容性的承诺-那时还没有面向公众的政策文件。但是，该标准确实发布了标准文档8（SD-8），该标准声明了标准库可以在版本之间进行的一小组更改类型，隐式定义了要准备的更改类型。 Java也是类似的：源在语言版本之间是兼容的，并且旧版本中的JAR文件将可以与新版本一起使用。

#### Go

并非所有语言都优先考虑相同程度的兼容性。 Go编程语言明确承诺大多数版本之间的源兼容性，但没有二进制兼容性。 您不能使用一种语言版本在Go中构建库，也不能将该库链接到使用另一种语言版本构建的Go程序中。

#### Abseil

Google的Abseil项目与Go十分相似，但需要注意一些重要的时间。我们不愿无限期地致力于兼容性：Abseil是我们内部大多数计算最繁重的服务的基础，我们认为这些服务可能会在未来许多年内使用。这意味着我们会谨慎保留更改的权利，尤其是在实施细节和ABI中进行更改，以便获得更好的性能。我们已经经历了太多的API实例，事实证明它们令人困惑并且容易出错。在无限的将来将这种已知的错误发布给成千上万的开发人员是不正确的。在内部，我们已经有大约2.5亿行C ++代码依赖此库，我们不会轻易对API进行更改，并必须做到这一点。为此，Abseil明确不承诺与ABI兼容，但承诺对API兼容略有限制：我们不会在对API造成重大破坏的情况下进行更改，除非提供了能够透明地将代码从旧API转换为新API的自动重构工具。我们认为，这极大地降低了意外发生的风险，并且使用户受益：无论依赖针对哪个版本编写，该依赖的用户和Abseil都应该能够使用最新版本。成本最高的应该是“run this tool”，并且大概率会将生成的补丁发送给中级依赖（liba或libb，前面的示例）。实际上，该项目足够新，因此我们无需进行任何重大的API更改。我们无法说这对整个生态系统的效果如何，但从理论上讲，这似乎在稳定性和易于升级之间取得了很好的平衡。

#### Boost

相比之下，Boost C ++库不保证版本之间的兼容性。当然，大多数代码都不会改变，但是“许多Boost库都得到了积极的维护和改进，因此并不总是能够与以前的版本向后兼容。“建议用户仅在项目生命周期中的某个阶段进行升级，在此期间某些更改不会引起问题。 Boost的目标与标准库或Abseil不同：Boost是实验验证的工具。 Boost stream中的特定发行版可能非常稳定，适合在许多项目中使用，但是Boost的项目目标并未优先考虑版本之间的兼容性-其他长期存在的项目可能会遇到一些问题。 Boost开发人员与标准库的开发人员一样都是标准库4的专家，这都不关乎技术专长：这完全取决于项目是否承诺或确定优先级。

在我们先前讨论的库中，很重要的一点是要认识到这些兼容性问题是软件工程问题，而不是编程问题。您可以下载不带兼容性保证的Boost等内容，并将其深深地嵌入到组织中最关键，使用寿命长的系统中；它会很好地工作。这里所有的关注点都是这些依赖关系将如何随着时间变化，跟上更新的步伐，使得开发人员面临软件维护的困难而不只是使软件功能正常运行。在Google内部，源源不断地向我们的工程师提供指导，以帮助他们考虑“我让它开始工作”与“正在以一种受支持的方式工作”之间的区别。这不足为奇：毕竟，它是Hyrum定律的基本应用。

概括地说：重要的是要认识到，依赖管理在编程任务和软件工程任务中具有完全不同的性质。如果您处于一个需要长期维护的问题空间中，则依赖管理很困难。如果您纯粹是为当今的需求而开发软件，而无需进行任何更新，那么完全可以合理地获取任意数量的随时可用的依赖项，而无需考虑如何负责任地使用它们或计划升级它们。即使违反SD-8中的所有内容并依赖Boost和Abseil的二进制兼容性来使您的程序今天可以正常工作……只要您不升级标准库，Boost或Abseil，并且不依赖你的任何内容。

### 导入依赖时考虑的问题

导入在编程项目中使用的依赖项几乎是不费力的：假设你已花足够时间确保它能够满足你的需要，并且不是隐秘的安全漏洞，那么与重新实现功能相比，重用通常总是简单的。即使该依赖承诺了他的兼容性，只要我们从未进行过升级，无论您在使用过程中违反了多少规则，依赖之上构建的任何内容都是可以正常工作的。但是，当我们从编程转向软件工程时，这些依赖变得更加昂贵，并且存在许多隐藏的成本和需要解决的问题。希望你在导入之前考虑了这些成本，并且希望知道你是在进行编程项目时还是在进行软件工程项目。

当Google的工程师尝试导入依赖项时，我们鼓励他们首先提出以下（不完整的）问题列表：

- 项目是否有可以运行的测试？
- 这些测试通过了吗？

- 谁在提供这种依赖？ 即使在“No warranty implied”的OSS项目中，也有大量的经验和技巧—比起从GitHub或npm中选择一个随机项目来说，依赖于C ++标准库或Java的Guava库的兼容性是一种更有效的做法。名声不是一切，但值得研究。
- 该项目希望实现什么样的兼容性？
- 项目是否详细说明了预计将支持哪种使用方式？
- 这个项目有多受欢迎？
- 我们将依赖这个项目多长时间？
- 项目多久进行一次重大更改？

此外，还选择了一些内部关注的问题：

- 在Google中实施该功能有多复杂？
- 我们必须采取什么激励措施来保持这种依赖关系的最新状态？
- 谁来执行升级？
- 我们预计执行升级有多困难？

我们自己的Russ Cox中更详细地介绍了这些内容。从长远来看，导入依赖和重新实现哪个更好，我们无法给出一个完美的公式来决定。我们自己常常失败于此。

### Google是如何导入依赖的

简而言之：我们可以做得更好。

任何给定的Google项目中绝大多数依赖都是内部开发的。这意味着我们内部依赖管理的绝大部分并不是真正的依赖管理，而是源代码控制（通过设计）。正如我们已经提到的，当提供者和使用者是同一组织的一部分并且具有适当的可见性和持续集成（CI；请参阅第23章）时，管理和控制添加依赖项所涉及的复杂性和风险要低得多。当您可以准确了解代码的使用方式并确切了解任何对代码更改会造成的影响时，依赖管理中的大多数问题就不再是问题了。源代码控制（当您控制有问题的项目时）比依赖管理（当您不这样做时）要容易得多。

在处理外部项目时，这种易用性就徐笑了。对于我们从OSS生态系统或商业合作伙伴导入的项目，这些依赖项被添加到我们的monorepo的单独目录中，该目录标记为third_party。让我们看一下如何将新的OSS项目添加到third_party。

假设Google的软件工程师Alice正在完成一个项目，并意识到当前有可用的开源解决方案。她真的很想尽快完成这个项目并进行演示，以便在度假前摆脱它。因此就会出现两种选择：是从头开始重新实现该功能，还是下载OSS程序包并将其添加到third_part中y。爱丽丝很可能认为更快的开发解决方案有意义：她下载了程序包，并遵循了我们的third_party中的一些步骤。这是一个非常简单的清单：确保使用我们的构建系统进行构建，确保该软件包没有现有版本，并确保至少有两名工程师来管理这个软件包，以在任何必要的情况下对该软件包进行维护。爱丽丝的队友鲍勃说：“是的，我会帮忙。”他们俩都不需要具有任何维护第三方软件包的经验，并且他们避免了解有关此软件包的实现的任何知识。但是，使用来解决预备演示问题的一部分，他们只能从项目中获得很少的经验。

从那时起，该软件包通常可供其他Google团队在其自己的项目中使用。添加其他依赖项的行为对Alice和Bob完全透明：他们可能完全不知道他们下载并承诺维护的软件包已经流行于谷歌团队中了。巧妙地，即使他们正在监视软件包的直接使用情况，他们也不一定会注意到其包的可传递使用量的增长。如果他们将其用于演示，而Charlie则从我们的Search基础架构内添加了依赖性，则该软件包将突然从相当无害的状态转变为重要Google系统的关键基础结构。但是，当查理（Charlie）考虑是否要添加此依赖项时，我们没有发现任何特别的信号。

现在，这种情况很可能很好。也许这种依赖关系写得很好，没有安全漏洞，也不受其他OSS项目的依赖。它可能会运行很多年而不进行更新。这样做不一定是明智的选择：外部更改可能对其进行了优化或添加了重要的新功能，或者在发现CVEs5之前清除了安全漏洞。程序包存在的时间越长，就可能产生更多的依赖关系（直接和间接）。该软件包保持的稳定性越强，我们越有可能使Hyrum Law更加依赖于检查third_party的版本的细节。

有一天，爱丽丝和鲍勃被告知升级至关重要。可能是软件包本身或依赖于它的OSS项目中的一个安全漏洞被迫升级。鲍勃（Bob）已过渡到管理人员，并且有一段时间没有接触过代码库了。自演示以来，爱丽丝已移至另一个团队，并且不再使用此软件包。没有人更改OWNERS文件。成千上万的项目间接依赖于此-我们不能在不破坏Search和其他十二个大团队的构建的情况下删除它。没有人对该程序包的实现细节有任何经验。爱丽丝不一定是一支拥有丰富经验的团队，可以克服随着时间的推移不做某件事情而累积的希鲁姆法则。

所有这些都是必要的：Alice和此软件包的其他用户都在进行昂贵且困难的升级，而安全团队则施加压力以立即解决此问题。在这种情况下，没有人会执行升级的实践，并且升级特别困难，因为它涵盖了许多较小的发行版，涵盖了从最初将软件包引入third_party到出现安全漏洞之间的整个时期。

我们的third_party政策不适用于这些常见不幸情况。 我们大致理解，我们需要更高的所有权限制，我们需要使定期更新变得更容易（并且更有意义），并且让第三方软件包更加独立变得十分重要。 困难之处在于，代码库维护人员和third_party领导者会说：“不，你不能使用可以完美解决你的开发问题的东西，因为我们没有资源来不断地更新每个人的新版本。” 受欢迎且没有兼容性承诺（例如Boost）的项目尤其危险：我们的开发人员可能非常熟悉使用该依赖关系来解决Google外部的编程问题，但是让它根深蒂固地融入我们的代码库结构是一个很大的风险。 目前，在未明确优先考虑稳定性的上游项目存在风险的前提下，我们的代码库的预期寿命为数十年。

# 从理论上讲，依赖管理

在了解了依赖管理的困难之处以及它会如何出错之后，让我们更具体地讨论一下我们正在试图解决的问题以及我们可能如何着手解决它们。在这一章中，我们回顾了“我们如何管理来自我们组织外部的代码 或者我们不能完全控制的代码):我们如何更新它，我们如何管理它所依赖的东西?”我们需要清楚的是，任何好的解决方案都要避免任何形式的需求冲突，包括菱角依赖版本冲突，即使是在一个动态的生态系统中，其中可能会添加新的依赖或其他需求(在网络中的任何位置)。我们还需要意识到时间的影响:所有软件都有错误，其中一些是安全关键，因此我们的部分依赖关系在足够长的一段时间内更新是至关重要的。

因此，一个稳定的依赖管理方案必须在时间和规模上灵活:我们不能假定依赖图中的任何特定节点具有无限的稳定性，也不能假定没有添加新的依赖(无论是在我们控制的代码中还是在我们依赖的代码中)。如果依赖项管理的解决方案可以防止依赖项之间的需求冲突问题，那么这就是一个好的解决方案。如果这样做时没有假定依赖项版本的稳定性或依赖项的扇形输出、组织之间的协调或可见性，或重要的计算资源，那么这是一个很好的解决方案。

当提出依赖管理的解决方案时，我们知道有四个常见的选择，它们至少显示了一些适当的属性:永远不改变，语义版本控制，捆绑你需要的所有东西(不是协调每个项目，而是每个发行版)，或者Live at Head。

# 没有任何改变(也就是静态依赖模型)

确保稳定依赖关系的最简单方法是永远不要改变它们:不要改变API，不要改变行为，什么都不要。只有在不破坏用户代码的情况下，才允许进行错误修复。这将兼容性和稳定性置于其他一切之上。显然，由于存在不定稳定性的假设，这种方案并不理想。如果，以某种方式，我们进入了一个安全问题和bug修复不再是问题，依赖关系不变的世界，那么Nothing Changes模型将非常吸引人:如果我们从可满足的约束开始，我们将能够无限期地维护该属性。

虽然这在长期内是不可持续的，但实际上，这是每个组织开始的地方:直到您证明了项目的预期寿命足够长，以至于有必要进行更改，我们很容易生活在一个假设没有任何更改的世界中。同样需要注意的是:对于大多数新组织来说，这可能是正确的模型。相对来说，很少有人知道您正在启动一个将存在几十年的项目，并且需要能够平稳地更新依赖项。更合理的做法是，希望稳定性是一个真正的选择，并假装依赖关系在项目的前几年是完全稳定的。

这种模式的缺点是，在足够长的一段时间内，它是错误的，而且没有明确的迹象表明你可以在多长时间内假装它是合法的。我们没有针对安全漏洞或其他可能迫使你升级依赖关系的关键问题的长期早期预警系统——而且由于依赖关系链，从理论上讲，一次升级可能会成为对整个依赖关系网络的强制升级。

在这个模型中，版本选择很简单:不需要做任何决定，因为没有版本。

# 语义版本控制

“今天我们如何管理依赖网络?”是语义版本控制(SemVer)SemVer是使用三个十进制分隔的整数(如2.4.72或1.1.4)表示某些依赖项(特别是库)的版本号的普遍做法。在最常见的惯例中，三个组件号代表主要版本、次要版本和补丁版本，这意味着改变的主版本号表示对现有API的改变，可能会破坏现有的使用，改变的次要版本号表示纯添加的功能，不应该破坏现有的使用，更改后的补丁版本保留给非影响api的实现细节和bug修复，这些被认为风险特别低。

通过SemVer对主要/次要/补丁版本的分离，假设版本需求通常可以表示为“任何更新的”，除非api不兼容的更改(主要版本更改)。通常，我们会看到“要求libbase≥1.5”，这个要求将兼容1.5的任何libbase，包括1.5.1，以及1.6以后的任何libbase，但不兼容libbase 1.4.9(缺少1.5中引入的API)或2。x (libbase中的一些api发生了不兼容的更改)。主要版本的变化是一个重大的不兼容性:因为现有的功能块已经改变(或被删除)，所有依赖项都存在潜在的不兼容性。每当一个依赖项使用另一个依赖项时，版本需求就会存在(显式或隐式):我们可能会看到“liba要求libbase≥1.5”和“libb要求libbase≥1.4.7”。

如果我们形式化这些需求，我们可以将依赖网络概念化为软件组件(节点)和它们之间的需求(边)的集合。这个网络中的边缘标签随着源节点版本的变化而变化，或者随着依赖项的添加(或删除)，或者由于源节点的变化而更新了SemVer需求(例如，需要在依赖项中添加新特性)。因为整个网络是随着时间的推移而异步变化的，因此找到一组相互兼容的依赖项来满足应用程序的所有传递性需求的过程是很有挑战性的SemVer的版本可满足性求解器在逻辑和算法研究中非常类似于sat求解器:给定一组约束(依赖边的版本要求)，我们能找到一组满足所有约束的节点版本吗?大多数包管理生态系统都构建在这些类型的图之上，由它们的SemVer sat解决方案管理。

SemVer及其sat解决程序并没有以任何方式保证存在一组给定依赖约束的解决方案。依赖约束不能被满足的情况会不断出现，正如我们已经看到的:如果一个低级组件(libbase)产生了主要数量的变化，并且依赖于它的一些库(libb而不是liba)升级了，我们就会遇到钻石依赖问题。

依赖管理的SemVer解决方案通常基于sat解决方案。版本选择就是运行一些算法来为网络中满足所有版本需求约束的依赖项找到一个版本分配。当不存在这样令人满意的版本分配时，我们通俗地称之为“依赖地狱”。

我们将在本章后面更详细地研究SemVer的一些限制。

# 捆绑分布模型

作为一个行业，几十年来我们已经看到了管理依赖项的强大模型的应用:一个组织收集一组依赖项，找到一组相互兼容的依赖项，并将该集合作为单个单元发布。这就是发生的情况，例如，在Linux发行版中——不能保证发行版中包含的各个部分在同一时间点被删除。事实上，更有可能的是，较低级别的依赖关系比较高级别的依赖关系更早一些，这只是为了考虑到集成它们所需要的时间。

这种“画一个更大的盒子，然后发布集合”的模式引入了全新的参与者:发行商。尽管所有独立依赖项的维护者可能对其他依赖项了解很少或根本不了解，但这些高级分发者参与了查找、修补和测试要包含的相互兼容版本集的过程。分销商是负责提出一组捆绑在一起的版本，测试这些版本以找到依赖树中的bug，并解决任何问题的工程师。

对于外部用户来说，只要您能够正确地依赖于这些捆绑发行版中的一个，这就可以很好地工作。这实际上与将依赖网络更改为单个聚合依赖并给出版本号是相同的。不是说，“我依赖于这些版本的这72个库”，而是“我依赖于RedHat版本N”，或者“我依赖于时间t的NPM图中的部分”。

在捆绑发行方式中，版本选择由专用发行方处理。

# Live at Head

我们Google中的一些人一直在推动的模式在理论上是合理的，但却给依赖网络的参与者带来了新的、昂贵的负担。它完全不像今天存在于OSS生态系统中的模型，而且作为一个产业，它不清楚如何从这里到那里。在像谷歌这样的组织范围内，这是昂贵但有效的，我们觉得它把大部分的成本和激励放到了正确的地方。我们称这种模式为“Live at Head”。它可以看作是基于干线开发的依赖管理扩展:在基于干线开发讨论源代码控制策略的地方，我们也在扩展该模型以应用于上游依赖关系。

Live at Head假定我们可以解除依赖关系，删除SemVer，并在提交之前依赖依赖提供商对整个生态系统进行测试。Live at Head是一个明确的尝试，试图从依赖管理的问题中拿出时间和选择:总是依赖于所有东西的当前版本，并且永远不要以一种让依赖者难以适应的方式改变任何东西。(无意中)改变API或行为的更改通常会被下游依赖项上的CI捕获，因此不应该提交。对于必须发生这种更改的情况(即出于安全原因)，只有在更新了下游依赖项或提供了自动工具来执行适当的更新之后，才应该进行这种中断。(此工具对于闭源下游消费者至关重要:其目标是允许任何用户在不了解使用或API的专业知识的情况下更新API的使用。这一特性显著减轻了破坏更改的“多数旁观者”成本。)在开源生态系统中，这种责任哲学上的转变一开始很难激发:让API提供者承担对其所有下游客户进行测试和更改的负担，是对API责任的重大修订提供者。

“我认为这是安全的或不安全。”相反，测试和CI系统被用来测试可见的依赖项，以从实验上确定一个更改有多安全。因此，对于只改变效率或实现细节的更改，所有可见的受影响的测试都可能通过，这表明没有明显的方法使该更改影响用户—提交是安全的。修改API中更明显的可观察部分(语法上或语义上)的更改通常会导致数百甚至数千个测试失败。然后，由提议变更的作者来决定解决这些失败所涉及的工作是否值得提交变更的结果价值。如果做得好，作者将与他们所有的依赖者一起提前解决测试失败(例如，解开测试中脆弱的假设)，并可能创建一个工具来尽可能多地执行必要的重构。

这里的激励结构和技术假设与其他情况有本质上的不同:我们假设存在单元测试和CI，我们假设API提供者将受到下游依赖是否会被打破的约束，我们假设API使用者将保持他们的测试通过，并以支持的方式依赖于他们的依赖。这在开源生态系统中(可以提前发布修复程序)比在隐藏/封闭源代码依赖项中工作得更好。API提供者在进行更改时受到激励，以便以一种可以顺利迁移到的方式进行更改。API消费者被鼓励保持他们的测试工作，以避免被标记为低信号测试和可能被跳过，减少该测试提供的保护。

在Live at Head方法中，版本选择是通过询问“所有内容的最新稳定版本是什么?”如果供应商负责任地做出改变，一切都会顺利进行。

# SemVer的局限性

Live at Head方法可能建立在公认的版本控制实践(基于主干的开发)上，但在很大程度上还没有得到规模化的验证。SemVer是目前依赖项管理的事实上的标准，但正如我们所建议的，它并非没有局限性。因为这是一种非常流行的方法，所以值得对其进行更详细的研究，并强调我们认为它可能存在的缺陷。

在SemVer的定义中，有很多东西需要解包，来解释点三层版本号的真正含义。这是承诺吗?或者为一个发布选择的版本号是一个估计?也就是说，当libbase的维护者剪掉一个新版本并选择是主要版本、次要版本还是补丁版本时，他们会说什么?是否可以证明从1.1.4升级到1.2.0是安全且容易的，因为只增加了API并修复了bug ?当然不是。在面对一个“简单的”API添加时，libbase的不良用户可能会做很多事情，导致构建中断或行为改变从根本上说，如果只考虑源API，就无法证明兼容性;你必须知道你问的是哪些东西的兼容性。

然而，当我们谈到依赖网络和应用于这些网络的sat解决程序时，这种“估计”兼容性的想法开始减弱。这个公式的基本问题是传统SAT中的节点值和SemVer依赖图中的版本值之间的差异。三sat图中的节点要么为True，要么为False。依赖关系图中的版本值(1.1.14)由维护者提供，作为对使用前一个版本的代码的新版本兼容性的估计。我们把所有版本满意的逻辑建立在一个不稳固的基础之上，把估计和自我认证当作绝对的。正如我们将看到的，即使这在有限的情况下行得通，总的来说，它不一定有足够的精确度来支撑一个健康的生态系统。

如果我们承认SemVer是一个有损耗的估计，并且只代表可能变化范围的一个子集，我们就可以开始把它看作是一个生硬的工具。从理论上讲，它作为一种速记方式工作得很好。在实践中，尤其是当我们在sat解决方案的基础上构建sat解决方案时，SemVer可能(也确实)会因为过度约束和保护不足而让我们失败。

# SemVer可能过度承诺

另一方面，SemVer的应用程序明确地假设API提供者对兼容性的估计是完全可预测的，更改分为三部分:破坏(通过修改或删除)、严格添加或不影响API。如果SemVer通过对语法和语义更改进行分类，完全忠实地表示更改的风险，那么我们如何描述给对时间敏感的API增加了一毫秒延迟的更改?或者，更有可能的是:我们如何描述改变日志输出格式的更改?或者改变我们导入外部依赖的顺序?或者改变结果在“无序”流中返回的顺序?仅仅因为这些更改不是相关API的语法或契约的一部分，就认为这些更改是“安全的”，这是否合理?如果文档上写着“这在将来可能会改变”怎么办?或者这个API被命名为“forinternalusebylibbaseonlydonottouchthisisireallymeanit ?”

从理论上讲，SemVer补丁版本只是改变实现细节，是“安全的”改变，这与谷歌的Hyrum定律相冲突——“当用户数量足够多时，你系统的每一个可观察的行为都会被某些人所依赖。”改变依赖项的导入顺序，或者改变“无序”生产者的输出顺序，就一定程度而言，会打破某些消费者(可能是错误地)所依赖的假设。“中断更改”这个术语本身是误导性的:有些更改在理论上是中断的，但在实践中是安全的(删除未使用的API)。还有一些修改在理论上是安全的，但在实践中会破坏客户端代码(任何我们早期Hyrum’s Law的例子)。我们可以看到这在任何SemVer /依赖关系管理系统的版本号要求系统允许补丁数量限制:如果你可以说仙女镇李坝社区需要libbase > 1.1.14而不是仙女镇李坝社区需要libbase 1.1,这显然是一个补丁版本中承认存在显著的差异。

隔离中的更改不具有破坏性或非破坏性——该语句只能在使用它的上下文中进行评估。“这是一个突破性的改变”的概念没有绝对的真理;可以看到，更改只会破坏(已知或未知)一组现有用户和用例。我们如何评估一个变更的现实本质上依赖于依赖项管理的SemVer公式中不存在的信息:下游用户如何使用这个依赖项?

正因为如此，SemVer约束求解器可能会报告你的依赖项在它们没有协同工作的时候协同工作，要么是因为bump被错误地应用了，要么是因为依赖项网络中的某些东西具有Hyrum’s Law依赖性，而这些依赖项并不被认为是可观察API表面的一部分。在这些情况下，您可能会有构建错误或运行时错误，它们的严重性没有理论上的上限。

# 动机

还有一个进一步的争论是SemVer并不总是激励稳定代码的创建。对于任意依赖项的维护者来说，不进行破坏性更改和破坏主要版本的系统激励是可变的。有些项目非常注重兼容性，会尽量避免主要版本的冲突。其他人则更激进，甚至有意在固定的时间表上修改主要版本。问题是，任何给定依赖项的大多数用户都是间接用户——他们没有任何重要的理由来意识到即将到来的变化。甚至大多数直接用户也不订阅邮件列表或其他发布通知。

所有这一切都表明，无论有多少用户会因为对一个流行的API进行不兼容的更改而感到不便，维护者要承担版本碰撞的一小部分成本。对于同样是用户的维护者来说，也可能存在破坏的动机:在没有遗留约束的情况下，总是更容易设计出更好的界面。这就是为什么我们认为项目应该发布关于兼容性、使用和破坏更改的明确的意图声明的部分原因。即使这些是最努力的，非绑定的，或被许多用户忽略的，它仍然为我们提供了一个出发点，在不引入这些冲突的激励结构的情况下，来判断一个破坏性的变更/主要版本碰撞是否“值得”。

Go和Clojure都很好地处理了这一点:在它们的标准包管理生态系统中，一个相当于主要版本碰撞的版本有望是一个全新的包。这有一种公正的感觉:如果您愿意打破您的包的向后兼容性，为什么我们要假装这是同一组api ?对提供商进行重新打包和重命名似乎是一项合理的工作，以换取他们接受核选项并抛弃向后兼容性。

最后，在这个过程中，人难免会犯错。一般来说，SemVer版本颠簸应该应用于语义变化，就像应用于语法变化一样;改变API的行为和改变它的结构一样重要。虽然可以开发工具来评估任何特定版本是否涉及到对一组公共api的语法更改，但识别是否存在有意义和有意的语义更改在计算上是不可实现的实际上，即使是识别语法变化的潜在工具也是有限的。在几乎所有情况下，对于任何给定的更改，都取决于API提供者的判断，是使用主要版本、次要版本还是补丁版本。如果您只依赖少数专业维护的依赖项，那么您对这种SemVer文书错误的预期暴露可能很低如果你的产品下面有一个由数千个依赖项组成的网络，你应该为人为错误造成的一些混乱做好准备。

# 最低版本选择

2018年，作为为Go编程语言构建包管理系统的系列文章的一部分，谷歌自己的Russ Cox描述了SemVer依赖管理的一个有趣的变体:最小版本选择(MVS)。当更新依赖网络中某些节点的版本时，可能需要将其依赖项更新为更新版本，以满足更新后的SemVer需求——这可能会触发进一步的更改。在大多数约束满足/版本选择公式中，会选择那些下游依赖项的最新可能版本:毕竟，您最终需要更新到这些新版本，对吗?

MVS做出了相反的选择:当liba的规范要求libbase≥1.7时，我们将直接尝试libbase 1.7，即使有1.8可用。这“产生高保真的构建，其中用户构建的依赖关系与作者开发的依赖关系尽可能接近。”在这一点上有一个非常重要的事实:当liba说它要求libbase≥1.7时，这几乎肯定意味着liba的开发者安装了libbase 1.7。假设维护者在发布之前执行了基本的测试，15我们至少有关于那个版本liba和版本1.7的互操作性测试的传闻证据。它不是CI或所有东西都经过了单元测试的证明，但它是某种东西。

如果没有来自对未来100%准确预测的准确输入约束，最好是尽可能实现最小的跳跃。就像在你的项目中投入一个小时的工作比一次性投入一年的工作更安全一样，在依赖更新中更小的步骤也更安全。MVS只是在每个受影响的依赖项需要的时候向前走，然后说，“好吧，我已经向前走了足够远，可以得到你想要的东西(而不是更远)。你为什么不做些测试看看情况是否良好?”

MVS思想的固有之处是承认新版本在实践中可能引入不兼容性，即使理论上的版本号不是这样说的。这是认识到SemVer的核心问题，无论是否使用MVS:在将软件更改压缩为版本号的过程中，会有一些保真度的损失。MVS提供了一些额外的实际保真度，试图产生最接近那些可能已经一起测试过的版本。这可能足以推动更大的依赖网络正常运行。不幸的是，我们还没有找到一个很好的方法来验证这个想法。陪审团仍然不确定是否MVS使SemVer“足够好”，没有解决基本的理论和激励问题的方法，但我们仍然相信，它代表了一个明显的改进，在SemVer约束的应用，因为他们今天使用。

# 那么，SemVer有用吗?

SemVer在有限的范围内运行良好。然而，认识到它实际上在说什么，不能说什么是非常重要的。SemVer将工作良好，只要:

•您的依赖提供商是准确和负责任的(以避免在SemVer碰撞中的人为错误)
•您的依赖关系是细粒度的(以避免错误的过度约束，当您的依赖关系中未使用/不相关的api被更新时，以及不满足SemVer需求的相关风险)
•所有api的所有使用都在预期的使用范围内(以避免被一个假设兼容的变化打破，无论是直接的还是在你依赖的代码传递)

如果依赖关系图中只有几个精心选择和维护良好的依赖关系，那么SemVer可能是一个非常合适的解决方案。

然而，我们在谷歌的经验表明，你不太可能拥有这三个属性中的任何一个，并让它们随着时间不断工作。规模往往是显示SemVer弱点的东西。随着依赖网络的扩大，每个依赖的大小和依赖的数量(以及由多个项目依赖于同一外部依赖网络产生的单一效应)，SemVer中复合保真度的损失将开始占主导地位。这些失败既表现为假阳性(理论上应该可以工作的实际上不兼容的版本)，也表现为假阴性(sat解决程序不允许兼容的版本，从而导致依赖地狱)。
