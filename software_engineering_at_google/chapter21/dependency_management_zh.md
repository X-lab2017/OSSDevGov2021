[toc]



# 依赖管理

依赖管理（我们无法控制的网络库，程序包和依赖的管理）是软件工程中最难理解且最具挑战性的问题之一。 依赖管理关注以下问题：如何在不同的外部依赖的版本之间进行更新？ 为此，我们如何描述版本？ 我们允许或预期依赖中存在哪些类型的更改？ 我们如何决定何时依赖于其他组织所写的代码？

为了进行比较，这里最相关的主题是源代码控制。 这两个领域都描述了我们如何使用源代码。 源代码管理涵盖了更简单的部分：我们在哪里检入内容？ 我们如何进行构建？ 在我们认可trunk-based的开发的价值之后，对于组织而言，大多数日常源代码控制问题都相当简单：“我有新东西，我要将其添加到哪个目录？”

依赖管理在时间和规模增加了额外的复杂性。在trunk-based控制问题上，当你进行改动时，你需要运行测试并且不影响现有的代码。这在对你使用一个共享代码库时，对事物是如何被使用的，并且可以触发构建和运行测试。依赖管理的重点是解决你掌控范围之外的代码出现变化时应该如何解决，这些代码你没有完全访问或可见性的权利。因为你的外部依赖不能与你的专用代码协调，他们更有可能毁坏你的构建，使你的测试失败。我们如何管理的？难道我们不应该采取外部依赖？我们是否应该要求外部依赖版本之间的强大一致性？我们什么时候更新到新版本？

扩展性使所有这些问题变得更加复杂，我们并不是在谈论单个依赖的导入，在通常情况下，我们依赖于整个外部依赖网络，当我们开始处理依赖网络，很容易碰到两个依赖在某个时间点上不兼容的问题。通常，发生这种情况是因为一个依赖项在没有某些前提的情况下会停止工作，而另一个依赖项则与该前提不兼容。有关如何管理一个单一的外部依赖简单的解决方案通常没有考虑到管理一个大型依赖网络的情况。我们会在本章大量讨论各种不同形式冲突的问题。

源代码控制和依赖管理是由以下问题分隔开的相关问题：“我们是否控制此子项目的开发/更新/管理？”例如，如果公司中的每个团队都有各自的存储库，目标和开发实践，则这些团队的代码的交互和管理将会在依赖管理做出更多的工作，相较于源代码控制。另一方面，具有（虚拟？）单个存储库（monorepo）的大型组织可以通过源代码控制策略进一步扩大规模，这是Google的方法。单独的开源项目当然可以视为单独的组织：未知项目与不必要协作项目之间的相互依赖关系是一个依赖关系管理问题。也许我们在此主题上最有力的建议是：在其他条件相同的情况下，相比依赖管理问题，更倾向于源代码控制问题。如果你可以更广泛地重新定义“组织”（整个公司而不是一个团队），那通常是一个很好的权衡。与依管理相比，源代码控制问题更容易考虑，并且处理起来也简单得多。

随着开放源代码软件（OSS）模型的不断发展并且扩展到新的领域，以及许多流行项目的依赖关系图随着时间的推移不断扩展，依赖管理可能已成为软件工程策略中最重要的问题。我们不再是在API之外的一层或两层上建立的不连接孤岛。现代软件是建立在高耸的依赖支柱上的。但是，仅仅因为我们可以建立这些支柱，并不意味着我们已经弄清楚了如何使用它们，并且能保证随着时间的推移这些支柱能够保持稳定。

在本章中，我们将研究依赖管理的一些特殊挑战，探索不同的解决方案（常见和新颖）及其局限性，并研究使用依赖的现实情况，包括我们在Google中的处理方式。首先要承认所有这些，这一点很重要：我们已经为这个问题投入了大量的思考，并且在重构和维护这些问题方面拥有丰富的经验，这些问题表明了现有方法的实际缺陷。我们没有第一手证据表明这个解决方案在整个组织中都能很好地发挥作用。总的来说，本章总结了我们所知道的行不通（或者至少在更大范围内行不通）以及我们认为有可能取得更好效果的解决方法。我们绝对不保证这里有所有的答案；如果有的话，我们不会将其称为软件工程中最重要的问题之一。

## 为什么依赖管理这么困难？

甚至定义依赖管理问题也向我们提出了一些不同寻常的挑战。在这个领域中，许多不成熟的解决方案都集中在一个过于狭窄的问题表述上：“我们如何导入本地开发的代码可以依赖的程序包？”这是必要但不充分的表述。诀窍不只是找到一种管理依赖关系的方法，还在于如何管理依赖关系及其随时间变化的里依赖网络。有些代码直接需要该网络的某些子集，其中某些仅由传递性依赖项引入。在足够长的时间内，该依赖项网络中的所有节点都将具有新版本，并且其中一些更新将很重要。我们如何管理其余依赖网络的级联升级？或者，特别是，如果我们不控制那些依赖关系，那么我们如何使所有依赖关系的相互兼容版本变得容易呢？我们如何分析依赖网络？我们如何管理该网络，尤其是面对不断增长的依赖关系图时？

### 需求的冲突和菱形依赖

依赖管理中的中心问题突出了从依赖网络而不是单个依赖进行思考的重要性。许多困难源于一个问题：当依赖关系网络中的两个节点有冲突的需求时，但你的组织同时依赖于这两个节点时，会发生什么？出现这种情况的原因有很多，从平台考虑因素（操作系统[OS]，语言版本，编译器版本等）到版本不兼容这类更为平凡的问题。版本不兼容作为无法满足的版本要求的典型示例是菱形依赖问题。尽管我们通常不会在依赖关系图中指明“正在使用哪个版本的编译器”之类的东西，但是这些冲突的需求问题中的大多数都是同构的，就是要向代表此需求的依赖关系图中“添加（隐藏）节点”。 ”因此，我们将主要就菱形依赖来讨论冲突的需求，但请记住，libbase实际上绝对是与依赖关系网络中的两个或多个节点的构建有关的任何软件。菱形依赖关系问题以及其他形式的冲突需求，至少需要三层依赖关系，如图21-1所示。

![image-20210509113746238](C:\Users\penggan\AppData\Roaming\Typora\typora-user-images\image-20210509113746238.png)

在此简化模型中，liba和libb都使用libbase，更高级别的组件libuser都使用liba和libb。 如果libbase曾经进行过不兼容的更改，则liba和libb作为独立组织的产品，有可能不会同时更新。 如果liba依赖于新的libbase版本，而libb依赖于旧版本，则libuser（也就是你的代码）没有通用的方法将所有东西组合在一起。 可以形成任意规模的菱形：在依赖关系的整个网络中，如果有一个低层节点需要同时处于两个不兼容的版本中（由于存在来自较高层的两条路径） 这两个版本的节点），就会出现问题。

不同的编程语言在不同程度上容忍了菱形依赖问题。对于某些语言，可以在一个版本中嵌入依赖关系的多个（隔离的）版本：从liba调用libbase可能会调用与从libb调用libbase相同的API的不同版本。例如，Java提供了相当完善的机制来重命名此类依赖关系提供的符号。同时，C ++在正常构建中对菱形依赖关系的容忍度几乎为零，并且它们很可能触发任意错误和未定义的行为（UB ），因为它明显违反了C ++的“一个定义规则”。你最多可以使用与Java类似的方法，将某些符号隐藏在动态链接库（DLL）中，或者在你分别构建和链接的情况下使用。但是，在我们所知道的所有编程语言中，这些解决方案充其量只是一部分的解决方案：可以通过调整函数名称来嵌入多个版本，但如果在依赖关系之间传递了类型，所有努力就都白费了。例如，根本没有办法将libbase v1中定义的map以语义一致的方式通过某些库传递给libbase v2提供的API。在的特定于语言的单独编译的库中隐藏或重命名实体可以为菱形依赖问题提供一定的缓冲，但在一般情况下解决不了问题。

如果遇到冲突的依赖需求问题，唯一简单的答案是向前或向后跳过这些依赖项的版本，以查找兼容的版本。 如果不可能，我们必须在本地解决有问题的依赖关系，这特别具有挑战性，因为首先发现不兼容的工程师可能不知道提供商和使用者之间不兼容的原因。 这是固有的：liba开发人员仍在与libbase v1兼容，并且libb开发人员已升级到v2。 只有同时参与这两个项目的开发人员才有机会发现问题，并且当然不能保证他们对libbase和liba足够熟悉，可以完成升级。 较简单的答案是降级libbase和libb，但是如果最初由于安全性问题而强制升级了，则不可以这样做。

用于依赖管理的策略和技术系统主要归结为以下问题：“我们如何在避免冲突需求的同时仍允许非协调组之间进行更改？” 如果你有解决里菱形依赖问题的一般形式的解决方案，并且可以在网络的各个级别上不断更改需求（依赖关系和平台需求），那么你已经描述了依赖关系管理解决方案的有趣部分。

## 引入依赖

用编程的术语来说，重用一些现有的基础结构显然比自己重新构建它更好。 这是显而易见的，并且是技术基础前进的一部分：如果每个新手都必须重新实现自己的JSON解析器和正则表达式引擎，我们将一事无成。 重用是很好的，特别是与从头开始开发高质量软件的成本相比。 只要你不下载木马软件，如果你的外部依赖满足编程任务的要求，则应使用外部依赖。

### 兼容性承诺

当我们开始考虑时间时，会出现一些更为复杂的取舍。 导入依赖项虽然避免了开发成本，但并不意味着是正确的选择。 但软件工程组织的人员随着时间变化时，我们还需要注意持续维护软件的成本。 即使我们引入了本来无意升级的依赖关系、发现安全漏洞或者改变软件运行平台，无论我们的意图如何，以及不断发展的依赖关系的网络都可以强迫我们进行升级。 在那一天到来时，升级价格会是多少？ 在仅使用某些依赖项的情况下，这些依赖项相比比其他依赖项可以更为明确的确定预期成本：假定了多少兼容性？ 假定改变了多少？ 如何处理变更？ 支持发行多长时间？

考虑拥有数百万用户的大型基础架构项目设置的示例及其兼容性承诺。我们建议依赖提供者应更清楚地了解这些问题的答案。 

#### C++

对于C ++标准库，该模型是几乎不确定的向后兼容性之一。针对较早版本的标准库构建的二进制文件有望与较新的标准构建并链接：该标准不仅提供API兼容性，而且还为二进制文件提供持续的向后兼容性，即ABI兼容性。各个平台对这种支持的重视程度各不相同。对于Linux上的gcc用户而言，大多数代码在大约十年的时间内都可以正常工作。该标准并未明确表示其对ABI兼容性的承诺-那时还没有面向公众的政策文件。但是，该标准确实发布了标准文档8（SD-8），该标准声明了标准库可以在版本之间进行的一小组更改类型，隐式定义了要准备的更改类型。 Java也是类似的：源在语言版本之间是兼容的，并且旧版本中的JAR文件将可以与新版本一起使用。

#### Go

并非所有语言都优先考虑相同程度的兼容性。 Go编程语言明确承诺大多数版本之间的源兼容性，但没有二进制兼容性。 您不能使用一种语言版本在Go中构建库，也不能将该库链接到使用另一种语言版本构建的Go程序中。

#### Abseil

Google的Abseil项目与Go十分相似，但需要注意一些重要的时间。我们不愿无限期地致力于兼容性：Abseil是我们内部大多数计算最繁重的服务的基础，我们认为这些服务可能会在未来许多年内使用。这意味着我们会谨慎保留更改的权利，尤其是在实施细节和ABI中进行更改，以便获得更好的性能。我们已经经历了太多的API实例，事实证明它们令人困惑并且容易出错。在无限的将来将这种已知的错误发布给成千上万的开发人员是不正确的。在内部，我们已经有大约2.5亿行C ++代码依赖此库，我们不会轻易对API进行更改，并必须做到这一点。为此，Abseil明确不承诺与ABI兼容，但承诺对API兼容略有限制：我们不会在对API造成重大破坏的情况下进行更改，除非提供了能够透明地将代码从旧API转换为新API的自动重构工具。我们认为，这极大地降低了意外发生的风险，并且使用户受益：无论依赖针对哪个版本编写，该依赖的用户和Abseil都应该能够使用最新版本。成本最高的应该是“run this tool”，并且大概率会将生成的补丁发送给中级依赖（liba或libb，前面的示例）。实际上，该项目足够新，因此我们无需进行任何重大的API更改。我们无法说这对整个生态系统的效果如何，但从理论上讲，这似乎在稳定性和易于升级之间取得了很好的平衡。

#### Boost

相比之下，Boost C ++库不保证版本之间的兼容性。当然，大多数代码都不会改变，但是“许多Boost库都得到了积极的维护和改进，因此并不总是能够与以前的版本向后兼容。“建议用户仅在项目生命周期中的某个阶段进行升级，在此期间某些更改不会引起问题。 Boost的目标与标准库或Abseil不同：Boost是实验验证的工具。 Boost stream中的特定发行版可能非常稳定，适合在许多项目中使用，但是Boost的项目目标并未优先考虑版本之间的兼容性-其他长期存在的项目可能会遇到一些问题。 Boost开发人员与标准库的开发人员一样都是标准库4的专家，这都不关乎技术专长：这完全取决于项目是否承诺或确定优先级。

在我们先前讨论的库中，很重要的一点是要认识到这些兼容性问题是软件工程问题，而不是编程问题。您可以下载不带兼容性保证的Boost等内容，并将其深深地嵌入到组织中最关键，使用寿命长的系统中；它会很好地工作。这里所有的关注点都是这些依赖关系将如何随着时间变化，跟上更新的步伐，使得开发人员面临软件维护的困难而不只是使软件功能正常运行。在Google内部，源源不断地向我们的工程师提供指导，以帮助他们考虑“我让它开始工作”与“正在以一种受支持的方式工作”之间的区别。这不足为奇：毕竟，它是Hyrum定律的基本应用。

概括地说：重要的是要认识到，依赖管理在编程任务和软件工程任务中具有完全不同的性质。如果您处于一个需要长期维护的问题空间中，则依赖管理很困难。如果您纯粹是为当今的需求而开发软件，而无需进行任何更新，那么完全可以合理地获取任意数量的随时可用的依赖项，而无需考虑如何负责任地使用它们或计划升级它们。即使违反SD-8中的所有内容并依赖Boost和Abseil的二进制兼容性来使您的程序今天可以正常工作……只要您不升级标准库，Boost或Abseil，并且不依赖你的任何内容。

### 导入依赖时考虑的问题

导入在编程项目中使用的依赖项几乎是不费力的：假设你已花足够时间确保它能够满足你的需要，并且不是隐秘的安全漏洞，那么与重新实现功能相比，重用通常总是简单的。即使该依赖承诺了他的兼容性，只要我们从未进行过升级，无论您在使用过程中违反了多少规则，依赖之上构建的任何内容都是可以正常工作的。但是，当我们从编程转向软件工程时，这些依赖变得更加昂贵，并且存在许多隐藏的成本和需要解决的问题。希望你在导入之前考虑了这些成本，并且希望知道你是在进行编程项目时还是在进行软件工程项目。

当Google的工程师尝试导入依赖项时，我们鼓励他们首先提出以下（不完整的）问题列表：

- 项目是否有可以运行的测试？
- 这些测试通过了吗？

- 谁在提供这种依赖？ 即使在“No warranty implied”的OSS项目中，也有大量的经验和技巧—比起从GitHub或npm中选择一个随机项目来说，依赖于C ++标准库或Java的Guava库的兼容性是一种更有效的做法。名声不是一切，但值得研究。
- 该项目希望实现什么样的兼容性？
- 项目是否详细说明了预计将支持哪种使用方式？
- 这个项目有多受欢迎？
- 我们将依赖这个项目多长时间？
- 项目多久进行一次重大更改？

此外，还选择了一些内部关注的问题：

- 在Google中实施该功能有多复杂？
- 我们必须采取什么激励措施来保持这种依赖关系的最新状态？
- 谁来执行升级？
- 我们预计执行升级有多困难？

我们自己的Russ Cox中更详细地介绍了这些内容。从长远来看，导入依赖和重新实现哪个更好，我们无法给出一个完美的公式来决定。我们自己常常失败于此。

### Google是如何导入依赖的

简而言之：我们可以做得更好。

任何给定的Google项目中绝大多数依赖都是内部开发的。这意味着我们内部依赖管理的绝大部分并不是真正的依赖管理，而是源代码控制（通过设计）。正如我们已经提到的，当提供者和使用者是同一组织的一部分并且具有适当的可见性和持续集成（CI；请参阅第23章）时，管理和控制添加依赖项所涉及的复杂性和风险要低得多。当您可以准确了解代码的使用方式并确切了解任何对代码更改会造成的影响时，依赖管理中的大多数问题就不再是问题了。源代码控制（当您控制有问题的项目时）比依赖管理（当您不这样做时）要容易得多。

在处理外部项目时，这种易用性就徐笑了。对于我们从OSS生态系统或商业合作伙伴导入的项目，这些依赖项被添加到我们的monorepo的单独目录中，该目录标记为third_party。让我们看一下如何将新的OSS项目添加到third_party。

假设Google的软件工程师Alice正在完成一个项目，并意识到当前有可用的开源解决方案。她真的很想尽快完成这个项目并进行演示，以便在度假前摆脱它。因此就会出现两种选择：是从头开始重新实现该功能，还是下载OSS程序包并将其添加到third_part中y。爱丽丝很可能认为更快的开发解决方案有意义：她下载了程序包，并遵循了我们的third_party中的一些步骤。这是一个非常简单的清单：确保使用我们的构建系统进行构建，确保该软件包没有现有版本，并确保至少有两名工程师来管理这个软件包，以在任何必要的情况下对该软件包进行维护。爱丽丝的队友鲍勃说：“是的，我会帮忙。”他们俩都不需要具有任何维护第三方软件包的经验，并且他们避免了解有关此软件包的实现的任何知识。但是，使用来解决预备演示问题的一部分，他们只能从项目中获得很少的经验。

从那时起，该软件包通常可供其他Google团队在其自己的项目中使用。添加其他依赖项的行为对Alice和Bob完全透明：他们可能完全不知道他们下载并承诺维护的软件包已经流行于谷歌团队中了。巧妙地，即使他们正在监视软件包的直接使用情况，他们也不一定会注意到其包的可传递使用量的增长。如果他们将其用于演示，而Charlie则从我们的Search基础架构内添加了依赖性，则该软件包将突然从相当无害的状态转变为重要Google系统的关键基础结构。但是，当查理（Charlie）考虑是否要添加此依赖项时，我们没有发现任何特别的信号。

现在，这种情况很可能很好。也许这种依赖关系写得很好，没有安全漏洞，也不受其他OSS项目的依赖。它可能会运行很多年而不进行更新。这样做不一定是明智的选择：外部更改可能对其进行了优化或添加了重要的新功能，或者在发现CVEs5之前清除了安全漏洞。程序包存在的时间越长，就可能产生更多的依赖关系（直接和间接）。该软件包保持的稳定性越强，我们越有可能使Hyrum Law更加依赖于检查third_party的版本的细节。

有一天，爱丽丝和鲍勃被告知升级至关重要。可能是软件包本身或依赖于它的OSS项目中的一个安全漏洞被迫升级。鲍勃（Bob）已过渡到管理人员，并且有一段时间没有接触过代码库了。自演示以来，爱丽丝已移至另一个团队，并且不再使用此软件包。没有人更改OWNERS文件。成千上万的项目间接依赖于此-我们不能在不破坏Search和其他十二个大团队的构建的情况下删除它。没有人对该程序包的实现细节有任何经验。爱丽丝不一定是一支拥有丰富经验的团队，可以克服随着时间的推移不做某件事情而累积的希鲁姆法则。

所有这些都是必要的：Alice和此软件包的其他用户都在进行昂贵且困难的升级，而安全团队则施加压力以立即解决此问题。在这种情况下，没有人会执行升级的实践，并且升级特别困难，因为它涵盖了许多较小的发行版，涵盖了从最初将软件包引入third_party到出现安全漏洞之间的整个时期。

我们的third_party政策不适用于这些常见不幸情况。 我们大致理解，我们需要更高的所有权限制，我们需要使定期更新变得更容易（并且更有意义），并且让第三方软件包更加独立变得十分重要。 困难之处在于，代码库维护人员和third_party领导者会说：“不，你不能使用可以完美解决你的开发问题的东西，因为我们没有资源来不断地更新每个人的新版本。” 受欢迎且没有兼容性承诺（例如Boost）的项目尤其危险：我们的开发人员可能非常熟悉使用该依赖关系来解决Google外部的编程问题，但是让它根深蒂固地融入我们的代码库结构是一个很大的风险。 目前，在未明确优先考虑稳定性的上游项目存在风险的前提下，我们的代码库的预期寿命为数十年。

# 从理论上讲，依赖管理

在了解了依赖管理的困难之处以及它会如何出错之后，让我们更具体地讨论一下我们正在试图解决的问题以及我们可能如何着手解决它们。在这一章中，我们回顾了“我们如何管理来自我们组织外部的代码 或者我们不能完全控制的代码):我们如何更新它，我们如何管理它所依赖的东西?”我们需要清楚的是，任何好的解决方案都要避免任何形式的需求冲突，包括菱角依赖版本冲突，即使是在一个动态的生态系统中，其中可能会添加新的依赖或其他需求(在网络中的任何位置)。我们还需要意识到时间的影响:所有软件都有错误，其中一些是安全关键，因此我们的部分依赖关系在足够长的一段时间内更新是至关重要的。

因此，一个稳定的依赖管理方案必须在时间和规模上灵活:我们不能假定依赖图中的任何特定节点具有无限的稳定性，也不能假定没有添加新的依赖(无论是在我们控制的代码中还是在我们依赖的代码中)。如果依赖项管理的解决方案可以防止依赖项之间的需求冲突问题，那么这就是一个好的解决方案。如果这样做时没有假定依赖项版本的稳定性或依赖项的扇形输出、组织之间的协调或可见性，或重要的计算资源，那么这是一个很好的解决方案。

当提出依赖管理的解决方案时，我们知道有四个常见的选择，它们至少显示了一些适当的属性:永远不改变，语义版本控制，捆绑你需要的所有东西(不是协调每个项目，而是每个发行版)，或者Live at Head。

# 没有任何改变(也就是静态依赖模型)

确保稳定依赖关系的最简单方法是永远不要改变它们:不要改变API，不要改变行为，什么都不要。只有在不破坏用户代码的情况下，才允许进行错误修复。这将兼容性和稳定性置于其他一切之上。显然，由于存在不定稳定性的假设，这种方案并不理想。如果，以某种方式，我们进入了一个安全问题和bug修复不再是问题，依赖关系不变的世界，那么Nothing Changes模型将非常吸引人:如果我们从可满足的约束开始，我们将能够无限期地维护该属性。

虽然这在长期内是不可持续的，但实际上，这是每个组织开始的地方:直到您证明了项目的预期寿命足够长，以至于有必要进行更改，我们很容易生活在一个假设没有任何更改的世界中。同样需要注意的是:对于大多数新组织来说，这可能是正确的模型。相对来说，很少有人知道您正在启动一个将存在几十年的项目，并且需要能够平稳地更新依赖项。更合理的做法是，希望稳定性是一个真正的选择，并假装依赖关系在项目的前几年是完全稳定的。

这种模式的缺点是，在足够长的一段时间内，它是错误的，而且没有明确的迹象表明你可以在多长时间内假装它是合法的。我们没有针对安全漏洞或其他可能迫使你升级依赖关系的关键问题的长期早期预警系统——而且由于依赖关系链，从理论上讲，一次升级可能会成为对整个依赖关系网络的强制升级。

在这个模型中，版本选择很简单:不需要做任何决定，因为没有版本。

# 语义版本控制

“今天我们如何管理依赖网络?”是语义版本控制(SemVer)SemVer是使用三个十进制分隔的整数(如2.4.72或1.1.4)表示某些依赖项(特别是库)的版本号的普遍做法。在最常见的惯例中，三个组件号代表主要版本、次要版本和补丁版本，这意味着改变的主版本号表示对现有API的改变，可能会破坏现有的使用，改变的次要版本号表示纯添加的功能，不应该破坏现有的使用，更改后的补丁版本保留给非影响api的实现细节和bug修复，这些被认为风险特别低。

通过SemVer对主要/次要/补丁版本的分离，假设版本需求通常可以表示为“任何更新的”，除非api不兼容的更改(主要版本更改)。通常，我们会看到“要求libbase≥1.5”，这个要求将兼容1.5的任何libbase，包括1.5.1，以及1.6以后的任何libbase，但不兼容libbase 1.4.9(缺少1.5中引入的API)或2。x (libbase中的一些api发生了不兼容的更改)。主要版本的变化是一个重大的不兼容性:因为现有的功能块已经改变(或被删除)，所有依赖项都存在潜在的不兼容性。每当一个依赖项使用另一个依赖项时，版本需求就会存在(显式或隐式):我们可能会看到“liba要求libbase≥1.5”和“libb要求libbase≥1.4.7”。

如果我们形式化这些需求，我们可以将依赖网络概念化为软件组件(节点)和它们之间的需求(边)的集合。这个网络中的边缘标签随着源节点版本的变化而变化，或者随着依赖项的添加(或删除)，或者由于源节点的变化而更新了SemVer需求(例如，需要在依赖项中添加新特性)。因为整个网络是随着时间的推移而异步变化的，因此找到一组相互兼容的依赖项来满足应用程序的所有传递性需求的过程是很有挑战性的SemVer的版本可满足性求解器在逻辑和算法研究中非常类似于sat求解器:给定一组约束(依赖边的版本要求)，我们能找到一组满足所有约束的节点版本吗?大多数包管理生态系统都构建在这些类型的图之上，由它们的SemVer sat解决方案管理。

SemVer及其sat解决程序并没有以任何方式保证存在一组给定依赖约束的解决方案。依赖约束不能被满足的情况会不断出现，正如我们已经看到的:如果一个低级组件(libbase)产生了主要数量的变化，并且依赖于它的一些库(libb而不是liba)升级了，我们就会遇到钻石依赖问题。

依赖管理的SemVer解决方案通常基于sat解决方案。版本选择就是运行一些算法来为网络中满足所有版本需求约束的依赖项找到一个版本分配。当不存在这样令人满意的版本分配时，我们通俗地称之为“依赖地狱”。

我们将在本章后面更详细地研究SemVer的一些限制。

# 捆绑分布模型

作为一个行业，几十年来我们已经看到了管理依赖项的强大模型的应用:一个组织收集一组依赖项，找到一组相互兼容的依赖项，并将该集合作为单个单元发布。这就是发生的情况，例如，在Linux发行版中——不能保证发行版中包含的各个部分在同一时间点被删除。事实上，更有可能的是，较低级别的依赖关系比较高级别的依赖关系更早一些，这只是为了考虑到集成它们所需要的时间。

这种“画一个更大的盒子，然后发布集合”的模式引入了全新的参与者:发行商。尽管所有独立依赖项的维护者可能对其他依赖项了解很少或根本不了解，但这些高级分发者参与了查找、修补和测试要包含的相互兼容版本集的过程。分销商是负责提出一组捆绑在一起的版本，测试这些版本以找到依赖树中的bug，并解决任何问题的工程师。

对于外部用户来说，只要您能够正确地依赖于这些捆绑发行版中的一个，这就可以很好地工作。这实际上与将依赖网络更改为单个聚合依赖并给出版本号是相同的。不是说，“我依赖于这些版本的这72个库”，而是“我依赖于RedHat版本N”，或者“我依赖于时间t的NPM图中的部分”。

在捆绑发行方式中，版本选择由专用发行方处理。

# Live at Head

我们Google中的一些人一直在推动的模式在理论上是合理的，但却给依赖网络的参与者带来了新的、昂贵的负担。它完全不像今天存在于OSS生态系统中的模型，而且作为一个产业，它不清楚如何从这里到那里。在像谷歌这样的组织范围内，这是昂贵但有效的，我们觉得它把大部分的成本和激励放到了正确的地方。我们称这种模式为“Live at Head”。它可以看作是基于干线开发的依赖管理扩展:在基于干线开发讨论源代码控制策略的地方，我们也在扩展该模型以应用于上游依赖关系。

Live at Head假定我们可以解除依赖关系，删除SemVer，并在提交之前依赖依赖提供商对整个生态系统进行测试。Live at Head是一个明确的尝试，试图从依赖管理的问题中拿出时间和选择:总是依赖于所有东西的当前版本，并且永远不要以一种让依赖者难以适应的方式改变任何东西。(无意中)改变API或行为的更改通常会被下游依赖项上的CI捕获，因此不应该提交。对于必须发生这种更改的情况(即出于安全原因)，只有在更新了下游依赖项或提供了自动工具来执行适当的更新之后，才应该进行这种中断。(此工具对于闭源下游消费者至关重要:其目标是允许任何用户在不了解使用或API的专业知识的情况下更新API的使用。这一特性显著减轻了破坏更改的“多数旁观者”成本。)在开源生态系统中，这种责任哲学上的转变一开始很难激发:让API提供者承担对其所有下游客户进行测试和更改的负担，是对API责任的重大修订提供者。

“我认为这是安全的或不安全。”相反，测试和CI系统被用来测试可见的依赖项，以从实验上确定一个更改有多安全。因此，对于只改变效率或实现细节的更改，所有可见的受影响的测试都可能通过，这表明没有明显的方法使该更改影响用户—提交是安全的。修改API中更明显的可观察部分(语法上或语义上)的更改通常会导致数百甚至数千个测试失败。然后，由提议变更的作者来决定解决这些失败所涉及的工作是否值得提交变更的结果价值。如果做得好，作者将与他们所有的依赖者一起提前解决测试失败(例如，解开测试中脆弱的假设)，并可能创建一个工具来尽可能多地执行必要的重构。

这里的激励结构和技术假设与其他情况有本质上的不同:我们假设存在单元测试和CI，我们假设API提供者将受到下游依赖是否会被打破的约束，我们假设API使用者将保持他们的测试通过，并以支持的方式依赖于他们的依赖。这在开源生态系统中(可以提前发布修复程序)比在隐藏/封闭源代码依赖项中工作得更好。API提供者在进行更改时受到激励，以便以一种可以顺利迁移到的方式进行更改。API消费者被鼓励保持他们的测试工作，以避免被标记为低信号测试和可能被跳过，减少该测试提供的保护。

在Live at Head方法中，版本选择是通过询问“所有内容的最新稳定版本是什么?”如果供应商负责任地做出改变，一切都会顺利进行。

# SemVer的局限性

Live at Head方法可能建立在公认的版本控制实践(基于主干的开发)上，但在很大程度上还没有得到规模化的验证。SemVer是目前依赖项管理的事实上的标准，但正如我们所建议的，它并非没有局限性。因为这是一种非常流行的方法，所以值得对其进行更详细的研究，并强调我们认为它可能存在的缺陷。

在SemVer的定义中，有很多东西需要解包，来解释点三层版本号的真正含义。这是承诺吗?或者为一个发布选择的版本号是一个估计?也就是说，当libbase的维护者剪掉一个新版本并选择是主要版本、次要版本还是补丁版本时，他们会说什么?是否可以证明从1.1.4升级到1.2.0是安全且容易的，因为只增加了API并修复了bug ?当然不是。在面对一个“简单的”API添加时，libbase的不良用户可能会做很多事情，导致构建中断或行为改变从根本上说，如果只考虑源API，就无法证明兼容性;你必须知道你问的是哪些东西的兼容性。

然而，当我们谈到依赖网络和应用于这些网络的sat解决程序时，这种“估计”兼容性的想法开始减弱。这个公式的基本问题是传统SAT中的节点值和SemVer依赖图中的版本值之间的差异。三sat图中的节点要么为True，要么为False。依赖关系图中的版本值(1.1.14)由维护者提供，作为对使用前一个版本的代码的新版本兼容性的估计。我们把所有版本满意的逻辑建立在一个不稳固的基础之上，把估计和自我认证当作绝对的。正如我们将看到的，即使这在有限的情况下行得通，总的来说，它不一定有足够的精确度来支撑一个健康的生态系统。

如果我们承认SemVer是一个有损耗的估计，并且只代表可能变化范围的一个子集，我们就可以开始把它看作是一个生硬的工具。从理论上讲，它作为一种速记方式工作得很好。在实践中，尤其是当我们在sat解决方案的基础上构建sat解决方案时，SemVer可能(也确实)会因为过度约束和保护不足而让我们失败。

# SemVer可能过度承诺

另一方面，SemVer的应用程序明确地假设API提供者对兼容性的估计是完全可预测的，更改分为三部分:破坏(通过修改或删除)、严格添加或不影响API。如果SemVer通过对语法和语义更改进行分类，完全忠实地表示更改的风险，那么我们如何描述给对时间敏感的API增加了一毫秒延迟的更改?或者，更有可能的是:我们如何描述改变日志输出格式的更改?或者改变我们导入外部依赖的顺序?或者改变结果在“无序”流中返回的顺序?仅仅因为这些更改不是相关API的语法或契约的一部分，就认为这些更改是“安全的”，这是否合理?如果文档上写着“这在将来可能会改变”怎么办?或者这个API被命名为“forinternalusebylibbaseonlydonottouchthisisireallymeanit ?”

从理论上讲，SemVer补丁版本只是改变实现细节，是“安全的”改变，这与谷歌的Hyrum定律相冲突——“当用户数量足够多时，你系统的每一个可观察的行为都会被某些人所依赖。”改变依赖项的导入顺序，或者改变“无序”生产者的输出顺序，就一定程度而言，会打破某些消费者(可能是错误地)所依赖的假设。“中断更改”这个术语本身是误导性的:有些更改在理论上是中断的，但在实践中是安全的(删除未使用的API)。还有一些修改在理论上是安全的，但在实践中会破坏客户端代码(任何我们早期Hyrum’s Law的例子)。我们可以看到这在任何SemVer /依赖关系管理系统的版本号要求系统允许补丁数量限制:如果你可以说仙女镇李坝社区需要libbase > 1.1.14而不是仙女镇李坝社区需要libbase 1.1,这显然是一个补丁版本中承认存在显著的差异。

隔离中的更改不具有破坏性或非破坏性——该语句只能在使用它的上下文中进行评估。“这是一个突破性的改变”的概念没有绝对的真理;可以看到，更改只会破坏(已知或未知)一组现有用户和用例。我们如何评估一个变更的现实本质上依赖于依赖项管理的SemVer公式中不存在的信息:下游用户如何使用这个依赖项?

正因为如此，SemVer约束求解器可能会报告你的依赖项在它们没有协同工作的时候协同工作，要么是因为bump被错误地应用了，要么是因为依赖项网络中的某些东西具有Hyrum’s Law依赖性，而这些依赖项并不被认为是可观察API表面的一部分。在这些情况下，您可能会有构建错误或运行时错误，它们的严重性没有理论上的上限。

# 动机

还有一个进一步的争论是SemVer并不总是激励稳定代码的创建。对于任意依赖项的维护者来说，不进行破坏性更改和破坏主要版本的系统激励是可变的。有些项目非常注重兼容性，会尽量避免主要版本的冲突。其他人则更激进，甚至有意在固定的时间表上修改主要版本。问题是，任何给定依赖项的大多数用户都是间接用户——他们没有任何重要的理由来意识到即将到来的变化。甚至大多数直接用户也不订阅邮件列表或其他发布通知。

所有这一切都表明，无论有多少用户会因为对一个流行的API进行不兼容的更改而感到不便，维护者要承担版本碰撞的一小部分成本。对于同样是用户的维护者来说，也可能存在破坏的动机:在没有遗留约束的情况下，总是更容易设计出更好的界面。这就是为什么我们认为项目应该发布关于兼容性、使用和破坏更改的明确的意图声明的部分原因。即使这些是最努力的，非绑定的，或被许多用户忽略的，它仍然为我们提供了一个出发点，在不引入这些冲突的激励结构的情况下，来判断一个破坏性的变更/主要版本碰撞是否“值得”。

Go和Clojure都很好地处理了这一点:在它们的标准包管理生态系统中，一个相当于主要版本碰撞的版本有望是一个全新的包。这有一种公正的感觉:如果您愿意打破您的包的向后兼容性，为什么我们要假装这是同一组api ?对提供商进行重新打包和重命名似乎是一项合理的工作，以换取他们接受核选项并抛弃向后兼容性。

最后，在这个过程中，人难免会犯错。一般来说，SemVer版本颠簸应该应用于语义变化，就像应用于语法变化一样;改变API的行为和改变它的结构一样重要。虽然可以开发工具来评估任何特定版本是否涉及到对一组公共api的语法更改，但识别是否存在有意义和有意的语义更改在计算上是不可实现的实际上，即使是识别语法变化的潜在工具也是有限的。在几乎所有情况下，对于任何给定的更改，都取决于API提供者的判断，是使用主要版本、次要版本还是补丁版本。如果您只依赖少数专业维护的依赖项，那么您对这种SemVer文书错误的预期暴露可能很低如果你的产品下面有一个由数千个依赖项组成的网络，你应该为人为错误造成的一些混乱做好准备。

# 最低版本选择

2018年，作为为Go编程语言构建包管理系统的系列文章的一部分，谷歌自己的Russ Cox描述了SemVer依赖管理的一个有趣的变体:最小版本选择(MVS)。当更新依赖网络中某些节点的版本时，可能需要将其依赖项更新为更新版本，以满足更新后的SemVer需求——这可能会触发进一步的更改。在大多数约束满足/版本选择公式中，会选择那些下游依赖项的最新可能版本:毕竟，您最终需要更新到这些新版本，对吗?

MVS做出了相反的选择:当liba的规范要求libbase≥1.7时，我们将直接尝试libbase 1.7，即使有1.8可用。这“产生高保真的构建，其中用户构建的依赖关系与作者开发的依赖关系尽可能接近。”在这一点上有一个非常重要的事实:当liba说它要求libbase≥1.7时，这几乎肯定意味着liba的开发者安装了libbase 1.7。假设维护者在发布之前执行了基本的测试，15我们至少有关于那个版本liba和版本1.7的互操作性测试的传闻证据。它不是CI或所有东西都经过了单元测试的证明，但它是某种东西。

如果没有来自对未来100%准确预测的准确输入约束，最好是尽可能实现最小的跳跃。就像在你的项目中投入一个小时的工作比一次性投入一年的工作更安全一样，在依赖更新中更小的步骤也更安全。MVS只是在每个受影响的依赖项需要的时候向前走，然后说，“好吧，我已经向前走了足够远，可以得到你想要的东西(而不是更远)。你为什么不做些测试看看情况是否良好?”

MVS思想的固有之处是承认新版本在实践中可能引入不兼容性，即使理论上的版本号不是这样说的。这是认识到SemVer的核心问题，无论是否使用MVS:在将软件更改压缩为版本号的过程中，会有一些保真度的损失。MVS提供了一些额外的实际保真度，试图产生最接近那些可能已经一起测试过的版本。这可能足以推动更大的依赖网络正常运行。不幸的是，我们还没有找到一个很好的方法来验证这个想法。陪审团仍然不确定是否MVS使SemVer“足够好”，没有解决基本的理论和激励问题的方法，但我们仍然相信，它代表了一个明显的改进，在SemVer约束的应用，因为他们今天使用。

# 那么，SemVer有用吗?

SemVer在有限的范围内运行良好。然而，认识到它实际上在说什么，不能说什么是非常重要的。SemVer将工作良好，只要:

•您的依赖提供商是准确和负责任的(以避免在SemVer碰撞中的人为错误)
•您的依赖关系是细粒度的(以避免错误的过度约束，当您的依赖关系中未使用/不相关的api被更新时，以及不满足SemVer需求的相关风险)
•所有api的所有使用都在预期的使用范围内(以避免被一个假设兼容的变化打破，无论是直接的还是在你依赖的代码传递)

如果依赖关系图中只有几个精心选择和维护良好的依赖关系，那么SemVer可能是一个非常合适的解决方案。

然而，我们在谷歌的经验表明，你不太可能拥有这三个属性中的任何一个，并让它们随着时间不断工作。规模往往是显示SemVer弱点的东西。随着依赖网络的扩大，每个依赖的大小和依赖的数量(以及由多个项目依赖于同一外部依赖网络产生的单一效应)，SemVer中复合保真度的损失将开始占主导地位。这些失败既表现为假阳性(理论上应该可以工作的实际上不兼容的版本)，也表现为假阴性(sat解决程序不允许兼容的版本，从而导致依赖地狱)。
## 无限资源的依赖性管理

在考虑依赖性管理解决方案时，有一个有用的思想实验：如果我们都能获得无限的计算资源，依赖性管理会是什么样子？也就是说，如果我们不受资源限制，而只受限于组织间的可见性和薄弱的协调，我们能期望的最好结果是什么？正如我们目前所看到的，该行业依赖SemVer的原因有三个。

- 它只需要本地信息（API供应商不需要知道下游用户的具体信息）

- 它不需要假设测试的可用性（在行业中还没有普及，但在未来十年肯定会向这个方向发展）、运行测试的计算资源或监测测试结果的CI系统的可用性。

- 这是现有的做法

对本地信息的 "要求 "并不是真正必要的，特别是因为依赖网络往往只在两种环境下形成。

- 在一个组织内

- 在开放源码软件生态系统内，即使项目不一定合作，源码也是可见的。

在这两种情况下，关于下游使用的重要信息都是可用的，即使它今天没有被轻易暴露或采取行动。也就是说，SemVer的有效主导地位的部分原因是我们选择忽略了理论上我们可以获得的信息。如果我们能够获得更多的计算资源，并且依赖性信息能够很容易地浮出水面，那么社区可能会找到它的用途。

尽管一个开放源码软件包可以有无数的闭源依赖，但常见的情况是，受欢迎的开放源码软件包在公开和私下都很受欢迎。依赖网络不会（不能）积极地混合公共和私人依赖关系：一般来说，有一个公共子集和一个单独的私人子图。

接下来，我们必须记住SemVer的意图。"据我估计，这种变化将很容易（或不容易）被采纳"。是否有更好的方式来传达这一信息？是的，以实践经验的形式，证明该变化易于采用。我们如何获得这种经验呢？如果我们大部分（或者至少是有代表性的样本）的依赖关系是公开的，那么我们就在每一个提议的改变中对这些依赖关系进行测试。有了足够多的这样的测试，我们至少有了一个统计学上的论据，即从实际的Hyrum's-Law意义上来说，这个变化是安全的。测试仍然通过，变化是好的--这并不重要，无论这是对API的影响，还是对bug的修复，或者是介于两者之间的东西；没有必要进行分类或估计。

想象一下，如果开放源码软件的生态系统转移到一个变化伴随着它们是否安全的证据的世界里。如果我们把计算成本排除在外，"这有多安全 "的真相来自于在下游依赖中运行受影响的测试。

即使没有正式的CI应用于整个OSS生态系统，我们当然也可以使用这样的依赖关系图和其他次要信号来做一个更有针对性的提交前分析。优先处理大量使用的依赖关系中的测试。优先考虑维护良好的依赖关系中的测试。优先考虑那些有提供良好信号和高质量测试结果历史的依赖关系中的测试。除了根据有可能给我们提供最多实验性变化质量信息的项目来确定测试的优先级外，我们还可以利用变化作者的信息来帮助估计风险和选择适当的测试策略。如果目标是 "任何人依赖的东西都不会以破坏的方式改变"，运行 "所有受影响 "的测试在理论上是必要的。如果我们认为目标更符合 "风险缓解"，那么统计论证就会成为一种更有吸引力（和成本效益）的方法。

在第12章中，我们确定了四种变化，从纯粹的重构到对现有功能的修改。考虑到基于CI的依赖性更新模型，我们可以开始将这些变化种类映射到类似于SemVer的模型上，对于这种模型，变化的作者估计风险并应用适当的测试水平。例如，仅修改内部API的纯重构变化可能被认为是低风险的，并证明仅在我们自己的项目和重要的直接依赖者中运行测试。另一方面，删除一个废弃的接口或改变可观察到的行为的变化可能需要我们进行尽可能多的测试。

为了应用这样的模式，我们需要对开放源码软件的生态系统进行哪些改变？不幸的是，有很多。

- 所有的依赖关系必须提供单元测试。尽管我们正不可阻挡地走向一个单元测试被广泛接受和无处不在的世界，但我们还没有到那一步。

- 大多数开放源码软件生态系统的依赖网络已经被理解。目前还不清楚是否有任何机制可以在该网络上进行图谱算法--信息是公开的，可用的，但实际上并没有被普遍索引或使用。许多软件包管理系统/依赖性管理生态系统允许你看到项目的依赖性，但不能看到反向的边缘，即依赖者。

- 用于执行CI的计算资源的可用性仍然非常有限。大多数开发人员没有机会使用构建和测试的计算集群。

- 依赖关系通常是以钉子的方式来表达的。作为 libbase 的维护者，如果 liba 和 libb 的依赖关系明确地依赖于 libbase 的特定固定版本，那么我们就不能通过测试来实验性地运行一个变化。

- 我们可能希望在 CI 计算中明确地包括历史和声誉。一个提议的修改会破坏一个有长期测试持续通过历史的项目，与一个最近才加入的、有因不相关原因而破坏的项目相比，它给了我们不同形式的证据。

这里面有一个规模问题：你要针对网络中每个依赖的哪些版本来测试预提交的变化？如果我们针对所有历史版本的完整组合进行测试，我们将燃烧一个真正惊人的计算资源，即使以谷歌的标准。这个版本选择策略的最明显的简化似乎是 "测试当前的稳定版本"（毕竟基于主干的开发是目标）。因此，在资源无限的情况下，依赖性管理的模式实际上就是 "活在当下 "的模式。悬而未决的问题是，该模型是否可以有效地适用于更实际的资源可用性，以及API提供者是否愿意承担更大的责任来测试其变化的实际安全性。认识到我们现有的低成本设施是对我们正在寻找的难以计算的真相的过度简化，仍然是一项有益的工作。

## 导出依赖关系

到目前为止，我们只谈到了承担依赖关系；也就是说，依赖于其他人编写的软件。同样值得思考的是，我们如何构建可以作为依赖的软件。这不仅仅是将软件打包并上传到资源库的机械性问题：我们需要考虑提供软件的好处、成本和风险，对我们和我们的潜在依赖者都是如此。

像 "开源库 "这种无害的、希望是慈善的行为，有两种主要的方式会成为一个组织可能的损失。首先，如果实施不力或维护不当，它最终会成为你的组织的声誉的阻力。正如Apache社区的说法，我们应该优先考虑 "社区大于代码"。如果你提供了很好的代码，但却是一个糟糕的社区成员，这仍然会对你的组织和更广泛的社区造成伤害。其次，如果你不能保持同步，一个善意的发布会成为工程效率的负担。只要有时间，所有的分叉都会变得昂贵。

### 例子：开源gflags

对于声誉的损失，可以考虑像谷歌在2006年左右的经验，开放我们的C++命令行标志库的情况。当然，回馈开源社区是一个纯粹的善举，不会回来困扰我们，对吗？遗憾的是，不是。一系列的原因合谋使这一善举变成了肯定会伤害我们的声誉，也可能会损害开放源码社区。

- 当时，我们没有能力进行大规模的重构，所以所有内部使用该库的东西都必须保持原样--我们不能把代码移到代码库的新位置。

- 我们将我们的资源库隔离成 "内部开发的代码"（如果需要分叉，可以自由复制，只要正确重命名）和 "可能有法律/许可问题的代码"（可能有更细微的使用要求）。

- 如果一个开放源码软件项目接受来自外部开发者的代码，这通常是一个法律问题--项目发起人并不拥有该贡献，他们只拥有该贡献的权利。

因此，gflags 项目注定是一个 "扔到墙外 "的版本，或者是一个断开连接的分叉。贡献给项目的补丁不能被重新纳入谷歌内部的原始源码，我们不能在我们的monorepo中移动项目，因为我们还没有掌握这种形式的重构，我们也不能让内部的一切都依赖于开放源码版本。

此外，像大多数组织一样，我们的优先级也随着时间的推移而转移和改变。在最初发布那个旗帜库的时候，我们对传统领域（网络应用、搜索）以外的产品感兴趣，包括像谷歌地球这样的产品，它有一个更传统的发布机制：为各种平台预编译的二进制文件。在21世纪末，在我们的monorepo中的一个库，特别是像flags这样的低级的东西，被用在各种平台上，这是不寻常的，但也不是没有。随着时间的推移和谷歌的成长，我们的关注点逐渐缩小，除了我们内部配置的工具链之外，很少有任何库是用其他东西构建的，然后部署到我们的生产机群。对于正确支持像旗帜这样的开放源码软件项目来说，"可移植性 "问题几乎是不可能维持的：我们的内部工具根本不支持这些平台，而我们的普通开发人员也不需要与外部工具互动。为了保持可移植性，这是一场持久战。

随着最初的作者和开放源码软件的支持者转到新的公司或新的团队，最终发现内部没有人真正支持我们的开放源码软件旗帜项目--没有人可以将这种支持与任何特定团队的优先事项联系起来。鉴于这不是某个团队的工作，也没人能说清楚为什么它很重要，所以我们基本上让这个项目在外部烂掉也就不奇怪了。随着时间的推移，内部和外部的版本慢慢地发生了分歧，最终一些外部的开发者把外部的版本分叉了，给了它一些适当的关注。

除了最初的 "哦，看，谷歌为开源世界贡献了一些东西 "之外，没有任何一部分让我们看起来很好，然而考虑到我们工程组织的优先级，每一个小部分都是有意义的。我们这些接近它的人已经学会了，"如果没有一个长期支持它的计划（和授权），就不要发布东西"。整个谷歌工程部是否已经学会了这一点，还有待观察。这是个大组织。

除了模糊的 "我们看起来很糟糕 "之外，这个故事还有一些部分说明了我们是如何受制于拙劣的发布/拙劣的维护的外部依赖所带来的技术问题。虽然flags库被共享但被忽视，但仍有一些谷歌支持的开源项目，或需要在我们的monorepo生态系统之外共享的项目。不出所料，那些其他项目的作者能够识别该库的内部和外部分叉之间的共同API子集。因为这个共同的子集在两个版本之间长期保持着相当的稳定性，对于那些在2008年到2017年之间有不寻常的可移植性要求的少数团队来说，它默默地成为 "这样做的方式"。他们的代码可以在内部和外部生态系统中构建，根据环境切换出分叉版本的标志库。

然后，由于不相关的原因，C++库团队开始调整内部标志实现中可观察但未记录的部分。在这一点上，所有依赖于不支持的外部分叉的稳定性和等价性的人都开始尖叫，他们的构建和发布突然被破坏了。一个价值在谷歌整个舰队的数千个聚合CPU的优化机会被大大推迟了，不是因为难以更新2.5亿行代码所依赖的API，而是因为极少数项目依赖于未承诺的、意想不到的东西。海勒姆法则再一次影响了软件的变化，在这种情况下，甚至是由不同组织维护的分叉API。

## 案例研究：AppEngine

一个更严重的将我们自己暴露在意外的技术依赖性的更大风险中的例子来自于发布谷歌的AppEngine服务。这项服务允许用户在现有框架的基础上用几种流行的编程语言之一编写他们的应用程序。只要应用程序是用适当的存储/状态管理模型编写的，AppEngine服务允许这些应用程序扩展到巨大的使用水平：备份存储和前端管理是由谷歌的生产基础设施按需管理和克隆的。

最初，AppEngine对Python的支持是使用旧版本的Python解释器运行的32位构建。AppEngine系统本身（当然）是在我们的monorepo中实现的，并与我们其他的通用工具一起构建，用Python和C++来支持后端。2014年，我们开始对Python运行时进行重大更新，同时安装C++编译器和标准库，其结果是我们有效地将 "用当前C++编译器构建的代码 "与 "使用更新的Python版本的代码 "联系起来--一个项目如果升级了这些依赖中的一个，就同时升级了另一个。对于大多数项目来说，这并不是一个问题。对于少数项目，由于边缘案例和Hyrum's Law，我们的语言平台专家最终做了一些调查和调试，以解除过渡的障碍。在一个可怕的Hyrum's Law与商业实际相结合的例子中，AppEngine发现它的许多用户，即我们的付费客户，不能（或不愿）更新：要么他们不想改变到较新的Python版本，要么他们负担不起从32位到64位Python的资源消耗变化。因为有一些客户为AppEngine的服务支付了大量的费用，AppEngine能够提出一个强有力的商业案例，即必须推迟强制切换到新的语言和编译器版本。这就意味着AppEngine的依赖关系中的每一段C++代码都必须与旧的编译器和标准库版本兼容：对该基础设施的任何错误修复或性能优化都必须跨版本兼容。这种情况持续了近三年。

有了足够多的用户，你的系统的任何 "可观察性 "都会被某个人所依赖。在谷歌，我们将所有的内部用户限制在我们的技术堆栈的范围内，并确保他们的使用与monorepo和代码索引系统的可见性，所以更容易确保有用的改变是可能的。当我们从源码控制转向依赖性管理，并失去了对代码使用情况的可见性，或者受到来自外部团体（尤其是那些付钱给你的团体）的竞争性优先权的影响时，要做出纯粹的工程权衡就变得更加困难。发布任何类型的API都会使你暴露在竞争性的优先级和外部人员不可预见的限制的可能性中。这并不是说你不应该发布API；这只是为了提醒你：API的外部用户比内部用户的维护成本高得多。

与外部世界分享代码，无论是作为开放源码发布还是作为闭源库发布，都不是一个简单的慈善问题（在开放源码的情况下）或商业机会（在闭源的情况下）。你无法监控的依赖性用户，在不同的组织中，有不同的优先级，最终会对该代码施加某种形式的海勒姆法则的惯性。特别是当你工作的时间尺度较长时，你不可能准确地预测可能成为有价值的必要或有用的变化的集合。当评估是否要发布一些东西时，要意识到长期的风险：外部共享的依赖关系随着时间的推移，修改的成本往往要高得多。

## 结论

依赖关系管理在本质上是一种挑战--我们正在寻找管理复杂的API表面和依赖关系网络的解决方案，这些依赖关系的维护者通常很少或根本没有协调的假设。管理依赖关系网络的事实上的标准是语义版本管理（SemVer），它对采用任何特定变化的感知风险提供了有损的总结。SemVer的前提是，在不知道有关的API是如何被消费的情况下，我们可以先验地预测变化的严重性。海勒姆定律告诉我们并非如此。然而，SemVer在小规模下工作得足够好，当我们包括MVS方法时，甚至更好。随着依赖网络规模的扩大，SemVer中的Hyrum定律问题和保真度损失使得管理新版本的选择越来越困难。

然而，我们有可能走向这样一个世界：维护者提供的兼容性估计（SemVer版本号）被放弃，而采用经验驱动的证据：运行受影响的下游包的测试。如果API供应商承担起更大的责任，针对他们的用户进行测试，并明确宣传预期的变化类型，我们就有可能在更大的范围内建立更高保真的依赖性网络。

## TL;DRs

- 更倾向于源控制问题，而不是依赖性管理问题：如果你能从你的组织中获得更多的代码，以获得更好的透明度和协调，这些都是重要的简化。

- 对于一个软件工程项目来说，添加一个依赖关系并不是免费的，建立一个 "持续的 "信任关系的复杂性是具有挑战性的。将依赖关系导入你的组织需要谨慎行事，并了解持续支持的成本。

- 依赖关系是一个合同：有付出就有收获，提供者和消费者在该合同中都有一些权利和责任。供应商应该清楚地了解他们在一段时间内试图承诺什么。

- SemVer是对 "人类认为这一变化的风险有多大 "的一种有损压缩的速记估计。SemVer与软件包管理器中的SAT解算器一起，将这些估计值升级为绝对值。这可能会导致过度约束（依赖性地狱）或不足约束（应该一起工作的版本却没有）。

- 相比之下，测试和CI提供了一组新版本是否能一起工作的实际证据。

- SemVer/包管理中的最小版本更新策略的保真度更高。这仍然依赖于人类能够准确地评估增量版本的风险，但明显提高了API提供者和消费者之间的联系已经被专家测试的机会。

- 单元测试、CI和（廉价）计算资源有可能改变我们对依赖性管理的理解和方法。这一阶段性变化要求从根本上改变业界对依赖性管理问题的看法，以及提供者和消费者的责任。

- 提供依赖性并不是免费的。"把它扔到墙上，然后忘掉 "会使你失去声誉，并成为兼容性的挑战。支持它的稳定性会限制你的选择并降低内部使用。没有稳定性的支持可能会损失商誉，或者使你面临重要的外部团体通过海勒姆法则依赖某些东西的风险，并使你的 "无稳定性 "计划陷入困境。